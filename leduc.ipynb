{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.utils.utils import remove_illegal\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import enum\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import rlcard\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "from rlcard.agents.nfsp_agent import ReservoirBuffer, DQNAgent\n",
    "from rlcard.agents import RandomAgent, LeducholdemHumanAgent as HumanAgent\n",
    "from rlcard.utils import get_device, set_seed, tournament, reorganize, Logger, plot_curve, remove_illegal, print_card\n",
    "\n",
    "\n",
    "class CFRAgent:\n",
    "    def __init__(self, env, model_name, model_path='./cfr_model'):\n",
    "        self.env = env\n",
    "        self.model_path = model_path\n",
    "        self.strategy = collections.defaultdict(list)\n",
    "        self.average_strategy = collections.defaultdict(np.array)\n",
    "        self.regrets = collections.defaultdict(np.array)\n",
    "        self.iteration = 0\n",
    "        self.use_raw = False\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def save(self):\n",
    "        with open(os.path.join('./', self.model_path, self.model_name + '-cfr-' + 'avg-strategy.pkl'), 'wb') as f:\n",
    "            pickle.dump(agent.average_strategy, f)\n",
    "\n",
    "        with open(os.path.join(self.model_path, self.model_name + '-cfr-' + 'strategy.pkl'), 'wb') as f:\n",
    "            pickle.dump(agent.strategy, f)\n",
    "\n",
    "        with open(os.path.join(self.model_path, self.model_name + '-cfr-' + 'regrets.pkl'), 'wb') as f:\n",
    "            pickle.dump(agent.regrets, f)\n",
    "            \n",
    "    def load(self):\n",
    "        with open(os.path.join(self.model_path, self.model_name + '-cfr-' + 'avg-strategy.pkl'), 'rb') as f:\n",
    "            self.average_strategy = pickle.load(f)\n",
    "        \n",
    "        with open(os.path.join(self.model_path, self.model_name + '-cfr-' + 'strategy.pkl'), 'rb') as f:\n",
    "            self.strategy = pickle.load(f)\n",
    "                  \n",
    "        with open(os.path.join(self.model_path, self.model_name + '-cfr-' + 'regrets.pkl'), 'rb') as f:\n",
    "            self.regrets = pickle.load(f)\n",
    "\n",
    "    def get_state(self, player_id):\n",
    "        state = self.env.get_state(player_id)\n",
    "        \n",
    "        # returns a tuple, current observation encoded as a string and a list of possible actions\n",
    "        return state['obs'].tostring(), list(state['legal_actions'].keys())\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        # train every player\n",
    "        self.iteration += 1\n",
    "        self.env.reset()\n",
    "        \n",
    "        for player_id in range(self.env.num_players):\n",
    "            reach_probs = np.ones(self.env.num_players)\n",
    "            self.cfr(reach_probs, player_id)\n",
    "        \n",
    "        self.update_strategy()\n",
    "            \n",
    "    def get_strategy_for_actions(self, obs, actions, strategy):\n",
    "        if obs not in strategy.keys():\n",
    "            # initialize to uniform distribution\n",
    "            action_probs = np.array([1.0/self.env.num_actions for _ in range(self.env.num_actions)]) # todo refactor this\n",
    "            self.strategy[obs] = action_probs\n",
    "        else:\n",
    "            action_probs = strategy[obs]\n",
    "        action_probs = remove_illegal(action_probs, actions)\n",
    "        return action_probs\n",
    "\n",
    "    def update_strategy(self):\n",
    "        ''' Update policy based on the current regrets\n",
    "        '''\n",
    "        for obs in self.regrets:\n",
    "            self.strategy[obs] = self.regret_matching(obs)\n",
    "            \n",
    "    def eval_step(self, state):\n",
    "        ''' Given a state, predict action based on average policy\n",
    "        Args:\n",
    "            state (numpy.array): State representation\n",
    "        Returns:\n",
    "            action (int): Predicted action\n",
    "            info (dict): A dictionary containing information\n",
    "        '''\n",
    "        probs = self.get_strategy_for_actions(state['obs'].tostring(), list(state['legal_actions'].keys()), self.average_strategy)\n",
    "        action = np.random.choice(len(probs), p=probs)\n",
    "\n",
    "        info = {}\n",
    "        info['probs'] = {state['raw_legal_actions'][i]: float(probs[list(state['legal_actions'].keys())[i]]) for i in range(len(state['legal_actions']))}\n",
    "\n",
    "        return action, info\n",
    "\n",
    "    \n",
    "    def regret_matching(self, obs):\n",
    "        regret = self.regrets[obs]\n",
    "        positive_regret_sum = sum([r for r in regret if r > 0])\n",
    "        \n",
    "        action_probs = np.zeros(self.env.num_actions)\n",
    "        if positive_regret_sum > 0:\n",
    "            for action in range(self.env.num_actions):\n",
    "                action_probs[action] = max(0.0, regret[action] / positive_regret_sum)\n",
    "        else:\n",
    "            for action in range(self.env.num_actions):\n",
    "                action_probs[action] = 1.0 / self.env.num_actions\n",
    "        return action_probs\n",
    "\n",
    "        \n",
    "    def cfr(self, reach_probs, player_id):\n",
    "        if self.env.is_over():\n",
    "            return self.env.get_payoffs()\n",
    "        \n",
    "        current_player = self.env.get_player_id()\n",
    "        \n",
    "        action_utilities = {} # expected payoff for every action?\n",
    "        infostate_utility = np.zeros(self.env.num_players) # get a handle on this, counterfactual reach probability?\n",
    "        \n",
    "        obs, legal_actions = self.get_state(current_player)\n",
    "        \n",
    "        # get the strategy for possible actions\n",
    "        action_probs = self.get_strategy_for_actions(obs, legal_actions, self.strategy)\n",
    "        \n",
    "        for action in legal_actions:\n",
    "            # recalculate reach probability for this action\n",
    "            action_prob = action_probs[action]\n",
    "            new_reach_probs = reach_probs.copy()\n",
    "            new_reach_probs[current_player] *= action_prob\n",
    "            \n",
    "            # traverse util you reach game node z, this will terminate at env.is_over()\n",
    "            self.env.step(action)\n",
    "            utility = self.cfr(new_reach_probs, player_id)\n",
    "            self.env.step_back()\n",
    "            \n",
    "            # counterfactual reach probability equals the sum of all reach probabilities\n",
    "            infostate_utility += action_prob * utility\n",
    "            action_utilities[action] = utility\n",
    "            \n",
    "        if not current_player == player_id:\n",
    "            return infostate_utility\n",
    "        \n",
    "        player_prob = reach_probs[current_player]\n",
    "        counterfactual_prob = (np.prod(reach_probs[:current_player]) *\n",
    "                                np.prod(reach_probs[current_player + 1:]))\n",
    "        player_state_utility = infostate_utility[current_player]\n",
    "        \n",
    "        # initialize records if they don't exist\n",
    "        if obs not in self.regrets:\n",
    "            self.regrets[obs] = np.zeros(self.env.num_actions)\n",
    "        if obs not in self.average_strategy:\n",
    "            self.average_strategy[obs] = np.zeros(self.env.num_actions)\n",
    "        \n",
    "        # calculate counterfactual regret for every action\n",
    "        for action in legal_actions:\n",
    "            action_prob = action_probs[action]\n",
    "            \n",
    "            # counterfactual regret is the utility of the action taking by the player - total utility of all actions \n",
    "            regret = counterfactual_prob * (action_utilities[action][current_player] - player_state_utility)\n",
    "            self.regrets[obs][action] += regret\n",
    "            self.average_strategy[obs][action] += self.iteration * player_prob * action_prob\n",
    "        return infostate_utility\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class AveragePolicyAgent(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.fc1 = nn.Linear(self.env.state_shape[0][0], 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, self.env.num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "class AveragePolicyAgent(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.fc1 = nn.Linear(self.env.state_shape[0][0], 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, self.env.num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "class NFSPAgent:\n",
    "    def __init__(self, env, device):\n",
    "        self.use_raw = False\n",
    "        self._device = device\n",
    "        \n",
    "        self.eta = 0.1\n",
    "        \n",
    "        self.sample_size = 32\n",
    "        \n",
    "        self._rl_agent = DQNAgent(\n",
    "            state_shape=env.state_shape[0],\n",
    "            num_actions=env.num_actions,\n",
    "            mlp_layers=[64, 64],\n",
    "            device=device)\n",
    "        self._m_sl = ReservoirBuffer(20000)\n",
    "        self._avg_policy_agent = AveragePolicyAgent(env)\n",
    "        self._avg_policy_agent.to(device)\n",
    "        self._avg_policy_optimizer = torch.optim.Adam(self._avg_policy_agent.parameters(), lr=0.005)\n",
    "        self.device = device\n",
    "        self.model_path = './models'\n",
    "        self.epochs = 0\n",
    "        \n",
    "    def eval_step(self, state):\n",
    "\n",
    "        obs = state['obs']\n",
    "        legal_actions = list(state['legal_actions'].keys())\n",
    "        if np.random.rand() < self.eta:\n",
    "            action, info = self._rl_agent.eval_step(state)\n",
    "        else:\n",
    "            action_probs = self._get_action_probs_from_policy(obs)\n",
    "            action_probs = remove_illegal(action_probs, legal_actions)\n",
    "            action = np.random.choice(len(action_probs), p=action_probs)\n",
    "            info = {}\n",
    "            info['probs'] = {state['raw_legal_actions'][i]: float(action_probs[list(state['legal_actions'].keys())[i]]) for i in range(len(state['legal_actions']))}\n",
    "        \n",
    "        return action, info\n",
    "    \n",
    "    def save(self, model_name):\n",
    "        torch.save({\n",
    "            'avg_policy': self._avg_policy_agent.state_dict(),\n",
    "            'q_policy_estimator': self._rl_agent.q_estimator.qnet.state_dict(),\n",
    "            'q_target_estimator': self._rl_agent.target_estimator.qnet.state_dict()\n",
    "        }, self.model_path + '/' + model_name)\n",
    "\n",
    "    def load(self, model_name):\n",
    "        checkpoint = torch.load(self.model_path + '/' + model_name)\n",
    "        self._avg_policy_agent.load_state_dict(checkpoint['avg_policy'])\n",
    "        self._rl_agent.q_estimator.qnet.load_state_dict(checkpoint['q_policy_estimator'])\n",
    "        self._rl_agent.target_estimator.qnet.load_state_dict(checkpoint['q_target_estimator'])\n",
    "    \n",
    "    def step(self, state):\n",
    "\n",
    "        obs = state['obs']\n",
    "        legal_actions = list(state['legal_actions'].keys())\n",
    "        if np.random.rand() < self.eta:\n",
    "            # make the rl agent act\n",
    "\n",
    "            action = self._rl_agent.step(state)\n",
    "            one_hot = np.zeros(env.num_actions)\n",
    "            one_hot[action] = 1\n",
    "\n",
    "            self._m_sl.add((obs, one_hot))\n",
    "        else:\n",
    "            # avg policy agent\n",
    "            action_probs = self._get_action_probs_from_policy(obs)\n",
    "            action_probs = remove_illegal(action_probs, legal_actions)\n",
    "            action = np.random.choice(len(action_probs), p=action_probs)\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def train_avg_policy(self):\n",
    "        if len(self._m_sl) < self.sample_size:\n",
    "            return None\n",
    "        \n",
    "        sample = self._m_sl.sample(self.sample_size)\n",
    "        \n",
    "        self._avg_policy_agent.zero_grad()\n",
    "        self._avg_policy_agent.eval()\n",
    "        \n",
    "        infostates = []\n",
    "        action_probs = []\n",
    "        for transition in sample:\n",
    "            infostates.append(transition[0])\n",
    "            action_probs.append(transition[1])\n",
    "        \n",
    "        infostates = torch.from_numpy(np.array(infostates)).float().to(self.device)\n",
    "        eval_action_probs = torch.from_numpy(np.array(action_probs)).float().to(self.device)\n",
    "        #eval_action_probs = eval_action_probs.long()\n",
    "        log_action_probs = self._avg_policy_agent(infostates)\n",
    "        #criterion = nn.MSELoss()\n",
    "        #loss = criterion(log_action_probs, eval_action_probs)\n",
    "        loss = -(eval_action_probs * log_action_probs).sum(dim=-1).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        self._avg_policy_optimizer.step()\n",
    "        self._avg_policy_agent.eval()\n",
    "        loss_total = loss.item()\n",
    "        return loss_total\n",
    "    \n",
    "    def _get_action_probs_from_policy(self, obs):\n",
    "        obs = torch.from_numpy(obs).float().to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            action_probs = self._avg_policy_agent(obs)\n",
    "        \n",
    "        action_probs = action_probs.cpu().numpy()\n",
    "        return np.exp(action_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 200000\n",
    "EVALUATE_EVERY = 1000\n",
    "EVALUATION_GAMES = 2000\n",
    "GAME = 'leduc-holdem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time = 2021-08-18 21:00:29.769026\n",
      "iteration 0\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  192\n",
      "  reward       |  -0.0115\n",
      "----------------------------------------\n",
      "iteration 1000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  192192\n",
      "  reward       |  0.8925\n",
      "----------------------------------------\n",
      "iteration 2000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  384192\n",
      "  reward       |  0.87575\n",
      "----------------------------------------\n",
      "iteration 3000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  576192\n",
      "  reward       |  0.8305\n",
      "----------------------------------------\n",
      "iteration 4000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  768192\n",
      "  reward       |  0.77975\n",
      "----------------------------------------\n",
      "iteration 5000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  960192\n",
      "  reward       |  0.8035\n",
      "----------------------------------------\n",
      "iteration 6000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1152192\n",
      "  reward       |  0.73925\n",
      "----------------------------------------\n",
      "iteration 7000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1344192\n",
      "  reward       |  0.75375\n",
      "----------------------------------------\n",
      "iteration 8000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1536192\n",
      "  reward       |  0.773\n",
      "----------------------------------------\n",
      "iteration 9000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1728192\n",
      "  reward       |  0.832\n",
      "----------------------------------------\n",
      "iteration 10000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1920192\n",
      "  reward       |  0.736\n",
      "----------------------------------------\n",
      "iteration 11000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  2112192\n",
      "  reward       |  0.839\n",
      "----------------------------------------\n",
      "iteration 12000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  2304192\n",
      "  reward       |  0.8565\n",
      "----------------------------------------\n",
      "iteration 13000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  2496192\n",
      "  reward       |  0.782\n",
      "----------------------------------------\n",
      "iteration 14000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  2688192\n",
      "  reward       |  0.7895\n",
      "----------------------------------------\n",
      "iteration 15000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  2880192\n",
      "  reward       |  0.83425\n",
      "----------------------------------------\n",
      "iteration 16000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  3072192\n",
      "  reward       |  0.8595\n",
      "----------------------------------------\n",
      "iteration 17000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  3264192\n",
      "  reward       |  0.74725\n",
      "----------------------------------------\n",
      "iteration 18000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  3456192\n",
      "  reward       |  0.8505\n",
      "----------------------------------------\n",
      "iteration 19000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  3648192\n",
      "  reward       |  0.89225\n",
      "----------------------------------------\n",
      "iteration 20000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  3840192\n",
      "  reward       |  0.78775\n",
      "----------------------------------------\n",
      "iteration 21000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4032192\n",
      "  reward       |  0.81525\n",
      "----------------------------------------\n",
      "iteration 22000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4224192\n",
      "  reward       |  0.867\n",
      "----------------------------------------\n",
      "iteration 23000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4416192\n",
      "  reward       |  0.8665\n",
      "----------------------------------------\n",
      "iteration 24000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4608192\n",
      "  reward       |  0.759\n",
      "----------------------------------------\n",
      "iteration 25000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4800192\n",
      "  reward       |  0.83425\n",
      "----------------------------------------\n",
      "iteration 26000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  4992192\n",
      "  reward       |  0.868\n",
      "----------------------------------------\n",
      "iteration 27000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  5184192\n",
      "  reward       |  0.8005\n",
      "----------------------------------------\n",
      "iteration 28000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  5376192\n",
      "  reward       |  0.843\n",
      "----------------------------------------\n",
      "iteration 29000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  5568192\n",
      "  reward       |  0.77975\n",
      "----------------------------------------\n",
      "iteration 30000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  5760192\n",
      "  reward       |  0.82225\n",
      "----------------------------------------\n",
      "iteration 31000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  5952192\n",
      "  reward       |  0.772\n",
      "----------------------------------------\n",
      "iteration 32000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  6144192\n",
      "  reward       |  0.8635\n",
      "----------------------------------------\n",
      "iteration 33000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  6336192\n",
      "  reward       |  0.75875\n",
      "----------------------------------------\n",
      "iteration 34000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  6528192\n",
      "  reward       |  0.83075\n",
      "----------------------------------------\n",
      "iteration 35000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  6720192\n",
      "  reward       |  0.82075\n",
      "----------------------------------------\n",
      "iteration 36000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  6912192\n",
      "  reward       |  0.80575\n",
      "----------------------------------------\n",
      "iteration 37000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  7104192\n",
      "  reward       |  0.87975\n",
      "----------------------------------------\n",
      "iteration 38000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  7296192\n",
      "  reward       |  0.81075\n",
      "----------------------------------------\n",
      "iteration 39000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  7488192\n",
      "  reward       |  0.79625\n",
      "----------------------------------------\n",
      "iteration 40000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  7680192\n",
      "  reward       |  0.84475\n",
      "----------------------------------------\n",
      "iteration 41000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  7872192\n",
      "  reward       |  0.82175\n",
      "----------------------------------------\n",
      "iteration 42000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  8064192\n",
      "  reward       |  0.86775\n",
      "----------------------------------------\n",
      "iteration 43000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  8256192\n",
      "  reward       |  0.8945\n",
      "----------------------------------------\n",
      "iteration 44000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  8448192\n",
      "  reward       |  0.8515\n",
      "----------------------------------------\n",
      "iteration 45000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  8640192\n",
      "  reward       |  0.8535\n",
      "----------------------------------------\n",
      "iteration 46000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  8832192\n",
      "  reward       |  0.8055\n",
      "----------------------------------------\n",
      "iteration 47000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9024192\n",
      "  reward       |  0.861\n",
      "----------------------------------------\n",
      "iteration 48000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9216192\n",
      "  reward       |  0.7765\n",
      "----------------------------------------\n",
      "iteration 49000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9408192\n",
      "  reward       |  0.83225\n",
      "----------------------------------------\n",
      "iteration 50000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9600192\n",
      "  reward       |  0.8295\n",
      "----------------------------------------\n",
      "iteration 51000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9792192\n",
      "  reward       |  0.82625\n",
      "----------------------------------------\n",
      "iteration 52000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  9984192\n",
      "  reward       |  0.6945\n",
      "----------------------------------------\n",
      "iteration 53000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  10176192\n",
      "  reward       |  0.8535\n",
      "----------------------------------------\n",
      "iteration 54000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  10368192\n",
      "  reward       |  0.934\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 55000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  10560192\n",
      "  reward       |  0.8205\n",
      "----------------------------------------\n",
      "iteration 56000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  10752192\n",
      "  reward       |  0.806\n",
      "----------------------------------------\n",
      "iteration 57000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  10944192\n",
      "  reward       |  0.914\n",
      "----------------------------------------\n",
      "iteration 58000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11136192\n",
      "  reward       |  0.74475\n",
      "----------------------------------------\n",
      "iteration 59000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11328192\n",
      "  reward       |  0.80175\n",
      "----------------------------------------\n",
      "iteration 60000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11520192\n",
      "  reward       |  0.822\n",
      "----------------------------------------\n",
      "iteration 61000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11712192\n",
      "  reward       |  0.8015\n",
      "----------------------------------------\n",
      "iteration 62000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  11904192\n",
      "  reward       |  0.83575\n",
      "----------------------------------------\n",
      "iteration 63000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  12096192\n",
      "  reward       |  0.86175\n",
      "----------------------------------------\n",
      "iteration 64000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  12288192\n",
      "  reward       |  0.7355\n",
      "----------------------------------------\n",
      "iteration 65000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  12480192\n",
      "  reward       |  0.83125\n",
      "----------------------------------------\n",
      "iteration 66000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  12672192\n",
      "  reward       |  0.864\n",
      "----------------------------------------\n",
      "iteration 67000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  12864192\n",
      "  reward       |  0.881\n",
      "----------------------------------------\n",
      "iteration 68000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  13056192\n",
      "  reward       |  0.86875\n",
      "----------------------------------------\n",
      "iteration 69000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  13248192\n",
      "  reward       |  0.75275\n",
      "----------------------------------------\n",
      "iteration 70000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  13440192\n",
      "  reward       |  0.889\n",
      "----------------------------------------\n",
      "iteration 71000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  13632192\n",
      "  reward       |  0.8875\n",
      "----------------------------------------\n",
      "iteration 72000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  13824192\n",
      "  reward       |  0.785\n",
      "----------------------------------------\n",
      "iteration 73000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14016192\n",
      "  reward       |  0.87375\n",
      "----------------------------------------\n",
      "iteration 74000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14208192\n",
      "  reward       |  0.78775\n",
      "----------------------------------------\n",
      "iteration 75000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14400192\n",
      "  reward       |  0.81625\n",
      "----------------------------------------\n",
      "iteration 76000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14592192\n",
      "  reward       |  0.759\n",
      "----------------------------------------\n",
      "iteration 77000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14784192\n",
      "  reward       |  0.89475\n",
      "----------------------------------------\n",
      "iteration 78000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  14976192\n",
      "  reward       |  0.8025\n",
      "----------------------------------------\n",
      "iteration 79000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  15168192\n",
      "  reward       |  0.789\n",
      "----------------------------------------\n",
      "iteration 80000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  15360192\n",
      "  reward       |  0.77025\n",
      "----------------------------------------\n",
      "iteration 81000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  15552192\n",
      "  reward       |  0.788\n",
      "----------------------------------------\n",
      "iteration 82000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  15744192\n",
      "  reward       |  0.77675\n",
      "----------------------------------------\n",
      "iteration 83000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  15936192\n",
      "  reward       |  0.749\n",
      "----------------------------------------\n",
      "iteration 84000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  16128192\n",
      "  reward       |  0.799\n",
      "----------------------------------------\n",
      "iteration 85000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  16320192\n",
      "  reward       |  0.829\n",
      "----------------------------------------\n",
      "iteration 86000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  16512192\n",
      "  reward       |  0.77975\n",
      "----------------------------------------\n",
      "iteration 87000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  16704192\n",
      "  reward       |  0.76275\n",
      "----------------------------------------\n",
      "iteration 88000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  16896192\n",
      "  reward       |  0.83825\n",
      "----------------------------------------\n",
      "iteration 89000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  17088192\n",
      "  reward       |  0.9155\n",
      "----------------------------------------\n",
      "iteration 90000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  17280192\n",
      "  reward       |  0.84125\n",
      "----------------------------------------\n",
      "iteration 91000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  17472192\n",
      "  reward       |  0.82525\n",
      "----------------------------------------\n",
      "iteration 92000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  17664192\n",
      "  reward       |  0.7535\n",
      "----------------------------------------\n",
      "iteration 93000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  17856192\n",
      "  reward       |  0.76025\n",
      "----------------------------------------\n",
      "iteration 94000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  18048192\n",
      "  reward       |  0.8465\n",
      "----------------------------------------\n",
      "iteration 95000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  18240192\n",
      "  reward       |  0.842\n",
      "----------------------------------------\n",
      "iteration 96000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  18432192\n",
      "  reward       |  0.86825\n",
      "----------------------------------------\n",
      "iteration 97000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  18624192\n",
      "  reward       |  0.79775\n",
      "----------------------------------------\n",
      "iteration 98000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  18816192\n",
      "  reward       |  0.88075\n",
      "----------------------------------------\n",
      "iteration 99000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19008192\n",
      "  reward       |  0.81875\n",
      "----------------------------------------\n",
      "iteration 100000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19200192\n",
      "  reward       |  0.87625\n",
      "----------------------------------------\n",
      "iteration 101000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19392192\n",
      "  reward       |  0.84925\n",
      "----------------------------------------\n",
      "iteration 102000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19584192\n",
      "  reward       |  0.8375\n",
      "----------------------------------------\n",
      "iteration 103000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19776192\n",
      "  reward       |  0.79925\n",
      "----------------------------------------\n",
      "iteration 104000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  19968192\n",
      "  reward       |  0.844\n",
      "----------------------------------------\n",
      "iteration 105000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  20160192\n",
      "  reward       |  0.86325\n",
      "----------------------------------------\n",
      "iteration 106000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  20352192\n",
      "  reward       |  0.90175\n",
      "----------------------------------------\n",
      "iteration 107000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  20544192\n",
      "  reward       |  0.86425\n",
      "----------------------------------------\n",
      "iteration 108000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  20736192\n",
      "  reward       |  0.91175\n",
      "----------------------------------------\n",
      "iteration 109000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  20928192\n",
      "  reward       |  0.858\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 110000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  21120192\n",
      "  reward       |  0.853\n",
      "----------------------------------------\n",
      "iteration 111000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  21312192\n",
      "  reward       |  0.8475\n",
      "----------------------------------------\n",
      "iteration 112000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  21504192\n",
      "  reward       |  0.90025\n",
      "----------------------------------------\n",
      "iteration 113000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  21696192\n",
      "  reward       |  0.83175\n",
      "----------------------------------------\n",
      "iteration 114000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  21888192\n",
      "  reward       |  0.7965\n",
      "----------------------------------------\n",
      "iteration 115000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  22080192\n",
      "  reward       |  0.795\n",
      "----------------------------------------\n",
      "iteration 116000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  22272192\n",
      "  reward       |  0.8645\n",
      "----------------------------------------\n",
      "iteration 117000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  22464192\n",
      "  reward       |  0.91975\n",
      "----------------------------------------\n",
      "iteration 118000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  22656192\n",
      "  reward       |  0.79325\n",
      "----------------------------------------\n",
      "iteration 119000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  22848192\n",
      "  reward       |  0.79125\n",
      "----------------------------------------\n",
      "iteration 120000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  23040192\n",
      "  reward       |  0.7815\n",
      "----------------------------------------\n",
      "iteration 121000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  23232192\n",
      "  reward       |  0.779\n",
      "----------------------------------------\n",
      "iteration 122000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  23424192\n",
      "  reward       |  0.82375\n",
      "----------------------------------------\n",
      "iteration 123000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  23616192\n",
      "  reward       |  0.821\n",
      "----------------------------------------\n",
      "iteration 124000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  23808192\n",
      "  reward       |  0.82625\n",
      "----------------------------------------\n",
      "iteration 125000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24000192\n",
      "  reward       |  0.809\n",
      "----------------------------------------\n",
      "iteration 126000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24192192\n",
      "  reward       |  0.80725\n",
      "----------------------------------------\n",
      "iteration 127000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24384192\n",
      "  reward       |  0.843\n",
      "----------------------------------------\n",
      "iteration 128000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24576192\n",
      "  reward       |  0.8475\n",
      "----------------------------------------\n",
      "iteration 129000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24768192\n",
      "  reward       |  0.77825\n",
      "----------------------------------------\n",
      "iteration 130000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  24960192\n",
      "  reward       |  0.85675\n",
      "----------------------------------------\n",
      "iteration 131000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  25152192\n",
      "  reward       |  0.8165\n",
      "----------------------------------------\n",
      "iteration 132000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  25344192\n",
      "  reward       |  0.8535\n",
      "----------------------------------------\n",
      "iteration 133000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  25536192\n",
      "  reward       |  0.824\n",
      "----------------------------------------\n",
      "iteration 134000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  25728192\n",
      "  reward       |  0.79975\n",
      "----------------------------------------\n",
      "iteration 135000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  25920192\n",
      "  reward       |  0.7475\n",
      "----------------------------------------\n",
      "iteration 136000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  26112192\n",
      "  reward       |  0.789\n",
      "----------------------------------------\n",
      "iteration 137000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  26304192\n",
      "  reward       |  0.9185\n",
      "----------------------------------------\n",
      "iteration 138000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  26496192\n",
      "  reward       |  0.85075\n",
      "----------------------------------------\n",
      "iteration 139000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  26688192\n",
      "  reward       |  0.8685\n",
      "----------------------------------------\n",
      "iteration 140000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  26880192\n",
      "  reward       |  0.861\n",
      "----------------------------------------\n",
      "iteration 141000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  27072192\n",
      "  reward       |  0.7925\n",
      "----------------------------------------\n",
      "iteration 142000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  27264192\n",
      "  reward       |  0.80625\n",
      "----------------------------------------\n",
      "iteration 143000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  27456192\n",
      "  reward       |  0.87125\n",
      "----------------------------------------\n",
      "iteration 144000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  27648192\n",
      "  reward       |  0.75475\n",
      "----------------------------------------\n",
      "iteration 145000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  27840192\n",
      "  reward       |  0.76875\n",
      "----------------------------------------\n",
      "iteration 146000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28032192\n",
      "  reward       |  0.8815\n",
      "----------------------------------------\n",
      "iteration 147000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28224192\n",
      "  reward       |  0.82825\n",
      "----------------------------------------\n",
      "iteration 148000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28416192\n",
      "  reward       |  0.812\n",
      "----------------------------------------\n",
      "iteration 149000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28608192\n",
      "  reward       |  0.8755\n",
      "----------------------------------------\n",
      "iteration 150000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28800192\n",
      "  reward       |  0.82975\n",
      "----------------------------------------\n",
      "iteration 151000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  28992192\n",
      "  reward       |  0.853\n",
      "----------------------------------------\n",
      "iteration 152000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  29184192\n",
      "  reward       |  0.881\n",
      "----------------------------------------\n",
      "iteration 153000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  29376192\n",
      "  reward       |  0.797\n",
      "----------------------------------------\n",
      "iteration 154000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  29568192\n",
      "  reward       |  0.90725\n",
      "----------------------------------------\n",
      "iteration 155000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  29760192\n",
      "  reward       |  0.891\n",
      "----------------------------------------\n",
      "iteration 156000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  29952192\n",
      "  reward       |  0.88725\n",
      "----------------------------------------\n",
      "iteration 157000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  30144192\n",
      "  reward       |  0.75925\n",
      "----------------------------------------\n",
      "iteration 158000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  30336192\n",
      "  reward       |  0.84175\n",
      "----------------------------------------\n",
      "iteration 159000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  30528192\n",
      "  reward       |  0.80825\n",
      "----------------------------------------\n",
      "iteration 160000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  30720192\n",
      "  reward       |  0.8065\n",
      "----------------------------------------\n",
      "iteration 161000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  30912192\n",
      "  reward       |  0.88225\n",
      "----------------------------------------\n",
      "iteration 162000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  31104192\n",
      "  reward       |  0.8075\n",
      "----------------------------------------\n",
      "iteration 163000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  31296192\n",
      "  reward       |  0.85525\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 164000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  31488192\n",
      "  reward       |  0.7655\n",
      "----------------------------------------\n",
      "iteration 165000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  31680192\n",
      "  reward       |  0.731\n",
      "----------------------------------------\n",
      "iteration 166000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  31872192\n",
      "  reward       |  0.814\n",
      "----------------------------------------\n",
      "iteration 167000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  32064192\n",
      "  reward       |  0.8675\n",
      "----------------------------------------\n",
      "iteration 168000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  32256192\n",
      "  reward       |  0.76575\n",
      "----------------------------------------\n",
      "iteration 169000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  32448192\n",
      "  reward       |  0.88475\n",
      "----------------------------------------\n",
      "iteration 170000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  32640192\n",
      "  reward       |  0.84525\n",
      "----------------------------------------\n",
      "iteration 171000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  32832192\n",
      "  reward       |  0.82875\n",
      "----------------------------------------\n",
      "iteration 172000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33024192\n",
      "  reward       |  0.77375\n",
      "----------------------------------------\n",
      "iteration 173000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33216192\n",
      "  reward       |  0.92025\n",
      "----------------------------------------\n",
      "iteration 174000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33408192\n",
      "  reward       |  0.79125\n",
      "----------------------------------------\n",
      "iteration 175000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33600192\n",
      "  reward       |  0.797\n",
      "----------------------------------------\n",
      "iteration 176000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33792192\n",
      "  reward       |  0.782\n",
      "----------------------------------------\n",
      "iteration 177000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  33984192\n",
      "  reward       |  0.82425\n",
      "----------------------------------------\n",
      "iteration 178000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  34176192\n",
      "  reward       |  0.83275\n",
      "----------------------------------------\n",
      "iteration 179000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  34368192\n",
      "  reward       |  0.858\n",
      "----------------------------------------\n",
      "iteration 180000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  34560192\n",
      "  reward       |  0.805\n",
      "----------------------------------------\n",
      "iteration 181000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  34752192\n",
      "  reward       |  0.78925\n",
      "----------------------------------------\n",
      "iteration 182000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  34944192\n",
      "  reward       |  0.84175\n",
      "----------------------------------------\n",
      "iteration 183000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  35136192\n",
      "  reward       |  0.77625\n",
      "----------------------------------------\n",
      "iteration 184000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  35328192\n",
      "  reward       |  0.81\n",
      "----------------------------------------\n",
      "iteration 185000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  35520192\n",
      "  reward       |  0.84075\n",
      "----------------------------------------\n",
      "iteration 186000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  35712192\n",
      "  reward       |  0.8255\n",
      "----------------------------------------\n",
      "iteration 187000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  35904192\n",
      "  reward       |  0.87725\n",
      "----------------------------------------\n",
      "iteration 188000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  36096192\n",
      "  reward       |  0.8125\n",
      "----------------------------------------\n",
      "iteration 189000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  36288192\n",
      "  reward       |  0.87475\n",
      "----------------------------------------\n",
      "iteration 190000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  36480192\n",
      "  reward       |  0.918\n",
      "----------------------------------------\n",
      "iteration 191000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  36672192\n",
      "  reward       |  0.85925\n",
      "----------------------------------------\n",
      "iteration 192000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  36864192\n",
      "  reward       |  0.902\n",
      "----------------------------------------\n",
      "iteration 193000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  37056192\n",
      "  reward       |  0.8775\n",
      "----------------------------------------\n",
      "iteration 194000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  37248192\n",
      "  reward       |  0.8305\n",
      "----------------------------------------\n",
      "iteration 195000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  37440192\n",
      "  reward       |  0.8175\n",
      "----------------------------------------\n",
      "iteration 196000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  37632192\n",
      "  reward       |  0.83825\n",
      "----------------------------------------\n",
      "iteration 197000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  37824192\n",
      "  reward       |  0.89025\n",
      "----------------------------------------\n",
      "iteration 198000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  38016192\n",
      "  reward       |  0.77525\n",
      "----------------------------------------\n",
      "iteration 199000\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  38208192\n",
      "  reward       |  0.7835\n",
      "----------------------------------------\n",
      "\n",
      "Logs saved in ./leduc\n",
      "Training end time = 2021-08-18 21:50:17.453271\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train cfr\n",
    "\n",
    "\n",
    "env = rlcard.make(GAME, config={'seed': 0, 'allow_step_back':True})\n",
    "eval_env = rlcard.make(GAME, config={'seed': 0})\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "agent = CFRAgent(env, 'leduc', 'models')\n",
    "eval_env.set_agents([agent, RandomAgent(num_actions=env.num_actions)])\n",
    "\n",
    "print(f'Training start time = {datetime.datetime.now()}')\n",
    "\n",
    "with Logger('./leduc') as logger:\n",
    "    for episode in range(EPISODES):\n",
    "        agent.train()\n",
    "        if episode % EVALUATE_EVERY == 0:\n",
    "            print(f'iteration {episode}')\n",
    "            logger.log_performance(env.timestep, tournament(eval_env, EVALUATION_GAMES)[0])\n",
    "    \n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
    "plot_curve(csv_path, fig_path, 'cfr')\n",
    "            \n",
    "print(f'Training end time = {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logs saved in ./leduc\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Logger('./leduc') as logger:\n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
    "plot_curve(csv_path, fig_path, 'cfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Running on the GPU\n",
      "\n",
      "----------------------------------------\n",
      "  timestep     |  1\n",
      "  reward       |  0.37525\n",
      "----------------------------------------\n",
      "INFO - Step 100, rl-loss: 1.1231166124343872\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 1100, rl-loss: 0.29753172397613525\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 1273, rl-loss: 1.17448699474334727\n",
      "----------------------------------------\n",
      "  timestep     |  8586\n",
      "  reward       |  0.91\n",
      "----------------------------------------\n",
      "INFO - Step 2100, rl-loss: 1.03228902816772466\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 2615, rl-loss: 1.75271606445312542\n",
      "----------------------------------------\n",
      "  timestep     |  18287\n",
      "  reward       |  0.88625\n",
      "----------------------------------------\n",
      "INFO - Step 3100, rl-loss: 1.53649425506591836\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 3922, rl-loss: 1.24653983116149934\n",
      "----------------------------------------\n",
      "  timestep     |  27908\n",
      "  reward       |  0.96375\n",
      "----------------------------------------\n",
      "INFO - Step 4100, rl-loss: 1.11597502231597905\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 5100, rl-loss: 0.63054239749908453\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 5277, rl-loss: 1.44968295097351074\n",
      "----------------------------------------\n",
      "  timestep     |  37894\n",
      "  reward       |  0.792\n",
      "----------------------------------------\n",
      "INFO - Step 6100, rl-loss: 1.93566870689392185\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 6667, rl-loss: 1.88484704494476326\n",
      "----------------------------------------\n",
      "  timestep     |  47819\n",
      "  reward       |  0.8675\n",
      "----------------------------------------\n",
      "INFO - Step 7100, rl-loss: 2.41704416275024447\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 8048, rl-loss: 2.27358150482177734\n",
      "----------------------------------------\n",
      "  timestep     |  57765\n",
      "  reward       |  0.82525\n",
      "----------------------------------------\n",
      "INFO - Step 8100, rl-loss: 2.02186179161071787\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 9100, rl-loss: 1.47589206695556646\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 9464, rl-loss: 3.22201585769653384\n",
      "----------------------------------------\n",
      "  timestep     |  67681\n",
      "  reward       |  0.8285\n",
      "----------------------------------------\n",
      "INFO - Step 10100, rl-loss: 1.99400949478149418\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 10880, rl-loss: 2.41159677505493166\n",
      "----------------------------------------\n",
      "  timestep     |  77665\n",
      "  reward       |  0.99325\n",
      "----------------------------------------\n",
      "INFO - Step 11100, rl-loss: 4.59584569931030353\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 12100, rl-loss: 0.41599076986312866\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 12355, rl-loss: 1.27941906452178963\n",
      "----------------------------------------\n",
      "  timestep     |  87886\n",
      "  reward       |  0.864\n",
      "----------------------------------------\n",
      "INFO - Step 13100, rl-loss: 0.75215154886245736\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 13754, rl-loss: 1.28763961791992197\n",
      "----------------------------------------\n",
      "  timestep     |  97913\n",
      "  reward       |  0.93475\n",
      "----------------------------------------\n",
      "INFO - Step 14100, rl-loss: 1.24256336688995365\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 15100, rl-loss: 1.62689757347106933\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 15227, rl-loss: 1.85728836059570317\n",
      "----------------------------------------\n",
      "  timestep     |  108019\n",
      "  reward       |  0.8815\n",
      "----------------------------------------\n",
      "INFO - Step 16100, rl-loss: 1.38049197196960454\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 16741, rl-loss: 0.47386327385902405\n",
      "----------------------------------------\n",
      "  timestep     |  118242\n",
      "  reward       |  0.87075\n",
      "----------------------------------------\n",
      "INFO - Step 17100, rl-loss: 1.51244187355041526\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 18100, rl-loss: 2.49777364730834966\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 18253, rl-loss: 2.26784157752990726\n",
      "----------------------------------------\n",
      "  timestep     |  128488\n",
      "  reward       |  0.86125\n",
      "----------------------------------------\n",
      "INFO - Step 19100, rl-loss: 4.45568513870239314\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 19787, rl-loss: 1.61230576038360626\n",
      "----------------------------------------\n",
      "  timestep     |  138754\n",
      "  reward       |  0.944\n",
      "----------------------------------------\n",
      "INFO - Step 20100, rl-loss: 2.18523597717285165\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 21100, rl-loss: 1.82043755054473887\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 21362, rl-loss: 5.81467342376709537\n",
      "----------------------------------------\n",
      "  timestep     |  149318\n",
      "  reward       |  1.00825\n",
      "----------------------------------------\n",
      "INFO - Step 22100, rl-loss: 0.87000501155853273\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 22889, rl-loss: 1.94430327415466336\n",
      "----------------------------------------\n",
      "  timestep     |  159533\n",
      "  reward       |  1.1435\n",
      "----------------------------------------\n",
      "INFO - Step 23100, rl-loss: 2.87517786026000987\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 24100, rl-loss: 5.62373638153076233\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 24364, rl-loss: 2.6557879447937014\n",
      "----------------------------------------\n",
      "  timestep     |  169968\n",
      "  reward       |  1.074\n",
      "----------------------------------------\n",
      "INFO - Step 25100, rl-loss: 2.15330696105957034\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 25892, rl-loss: 1.4675021171569824\n",
      "----------------------------------------\n",
      "  timestep     |  180368\n",
      "  reward       |  1.03575\n",
      "----------------------------------------\n",
      "INFO - Step 26100, rl-loss: 5.4891920089721687\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 27100, rl-loss: 1.3740540742874146\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 27433, rl-loss: 1.56500244140625177\n",
      "----------------------------------------\n",
      "  timestep     |  190722\n",
      "  reward       |  1.10475\n",
      "----------------------------------------\n",
      "INFO - Step 28100, rl-loss: 2.3166494369506836\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 28970, rl-loss: 5.1565198898315439\n",
      "----------------------------------------\n",
      "  timestep     |  201045\n",
      "  reward       |  1.03825\n",
      "----------------------------------------\n",
      "INFO - Step 29100, rl-loss: 3.0962224006652835\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 30100, rl-loss: 3.0827450752258375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 30543, rl-loss: 3.2600500583648682\n",
      "----------------------------------------\n",
      "  timestep     |  211479\n",
      "  reward       |  1.1225\n",
      "----------------------------------------\n",
      "INFO - Step 31100, rl-loss: 3.2836749553680424\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 32100, rl-loss: 3.3076977729797363\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 32103, rl-loss: 1.6584951877593994\n",
      "----------------------------------------\n",
      "  timestep     |  221717\n",
      "  reward       |  1.00725\n",
      "----------------------------------------\n",
      "INFO - Step 33100, rl-loss: 1.5689730644226074\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 33673, rl-loss: 2.6852335929870605\n",
      "----------------------------------------\n",
      "  timestep     |  232158\n",
      "  reward       |  1.12475\n",
      "----------------------------------------\n",
      "INFO - Step 34100, rl-loss: 2.0979180335998535\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 35100, rl-loss: 1.1819334030151367\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 35243, rl-loss: 2.8559727668762207\n",
      "----------------------------------------\n",
      "  timestep     |  242528\n",
      "  reward       |  0.9935\n",
      "----------------------------------------\n",
      "INFO - Step 36100, rl-loss: 6.9378523826599122\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 36774, rl-loss: 1.4304351806640625\n",
      "----------------------------------------\n",
      "  timestep     |  252773\n",
      "  reward       |  1.12425\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 37100, rl-loss: 4.0835275650024417\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 38100, rl-loss: 1.3293745517730713\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 38316, rl-loss: 5.8989858627319346\n",
      "----------------------------------------\n",
      "  timestep     |  263177\n",
      "  reward       |  0.9445\n",
      "----------------------------------------\n",
      "INFO - Step 39100, rl-loss: 2.9135904312133793\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 39952, rl-loss: 2.2846164703369142\n",
      "----------------------------------------\n",
      "  timestep     |  273761\n",
      "  reward       |  0.96925\n",
      "----------------------------------------\n",
      "INFO - Step 40100, rl-loss: 4.6686601638793945\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 41100, rl-loss: 4.1418018341064455\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 41499, rl-loss: 2.4759092330932617\n",
      "----------------------------------------\n",
      "  timestep     |  284129\n",
      "  reward       |  1.0805\n",
      "----------------------------------------\n",
      "INFO - Step 42100, rl-loss: 6.9120802879333599\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 43012, rl-loss: 1.3528243303298955\n",
      "----------------------------------------\n",
      "  timestep     |  294628\n",
      "  reward       |  0.96775\n",
      "----------------------------------------\n",
      "INFO - Step 43100, rl-loss: 5.8775444030761725\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 44100, rl-loss: 3.1865754127502441\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 44548, rl-loss: 1.3081612586975098\n",
      "----------------------------------------\n",
      "  timestep     |  304964\n",
      "  reward       |  1.04425\n",
      "----------------------------------------\n",
      "INFO - Step 45100, rl-loss: 3.3320689201354985\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 46100, rl-loss: 1.4586720466613778\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 46112, rl-loss: 3.0004537105560303\n",
      "----------------------------------------\n",
      "  timestep     |  315456\n",
      "  reward       |  0.9105\n",
      "----------------------------------------\n",
      "INFO - Step 47100, rl-loss: 2.4834539890289307\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 47647, rl-loss: 3.1962835788726807\n",
      "----------------------------------------\n",
      "  timestep     |  325871\n",
      "  reward       |  0.95075\n",
      "----------------------------------------\n",
      "INFO - Step 48100, rl-loss: 3.2372913360595703\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 49100, rl-loss: 2.7589912414550783\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 49186, rl-loss: 2.8960103988647468\n",
      "----------------------------------------\n",
      "  timestep     |  336472\n",
      "  reward       |  0.912\n",
      "----------------------------------------\n",
      "INFO - Step 50100, rl-loss: 6.1596832275390625\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 50777, rl-loss: 1.9623253345489502\n",
      "----------------------------------------\n",
      "  timestep     |  347039\n",
      "  reward       |  0.8765\n",
      "----------------------------------------\n",
      "INFO - Step 51100, rl-loss: 2.1167657375335693\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 52100, rl-loss: 4.1091203689575195\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 52399, rl-loss: 2.5796513557434085\n",
      "----------------------------------------\n",
      "  timestep     |  357635\n",
      "  reward       |  0.978\n",
      "----------------------------------------\n",
      "INFO - Step 53100, rl-loss: 2.3520345687866212\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 53934, rl-loss: 2.2134423255920417\n",
      "----------------------------------------\n",
      "  timestep     |  368028\n",
      "  reward       |  0.96025\n",
      "----------------------------------------\n",
      "INFO - Step 54100, rl-loss: 2.9124050140380869\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 55100, rl-loss: 1.3891773223876953\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 55482, rl-loss: 5.3507413864135742\n",
      "----------------------------------------\n",
      "  timestep     |  378660\n",
      "  reward       |  0.9385\n",
      "----------------------------------------\n",
      "INFO - Step 56100, rl-loss: 1.5544480085372925\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 57028, rl-loss: 1.9340462684631348\n",
      "----------------------------------------\n",
      "  timestep     |  389143\n",
      "  reward       |  0.90225\n",
      "----------------------------------------\n",
      "INFO - Step 57100, rl-loss: 5.0858297348022462\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 58100, rl-loss: 2.5349142551422125\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 58543, rl-loss: 3.4090788364410413\n",
      "----------------------------------------\n",
      "  timestep     |  399433\n",
      "  reward       |  0.952\n",
      "----------------------------------------\n",
      "INFO - Step 59100, rl-loss: 5.5293407440185556\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 60084, rl-loss: 3.4013686180114746\n",
      "----------------------------------------\n",
      "  timestep     |  409944\n",
      "  reward       |  0.962\n",
      "----------------------------------------\n",
      "INFO - Step 60100, rl-loss: 3.0741996765136726\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 61100, rl-loss: 3.5954301357269287\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 61629, rl-loss: 3.8322107791900635\n",
      "----------------------------------------\n",
      "  timestep     |  420360\n",
      "  reward       |  0.96775\n",
      "----------------------------------------\n",
      "INFO - Step 62100, rl-loss: 2.8689191341400146\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 63100, rl-loss: 2.50814485549926763\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 63173, rl-loss: 3.3922412395477295\n",
      "----------------------------------------\n",
      "  timestep     |  430761\n",
      "  reward       |  1.03975\n",
      "----------------------------------------\n",
      "INFO - Step 64100, rl-loss: 2.8441371917724617\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 64741, rl-loss: 6.2138175964355477\n",
      "----------------------------------------\n",
      "  timestep     |  441209\n",
      "  reward       |  0.9945\n",
      "----------------------------------------\n",
      "INFO - Step 65100, rl-loss: 5.6770038604736335\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 66100, rl-loss: 0.89365702867507934\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 66326, rl-loss: 3.5141420364379883\n",
      "----------------------------------------\n",
      "  timestep     |  451819\n",
      "  reward       |  0.99325\n",
      "----------------------------------------\n",
      "INFO - Step 67100, rl-loss: 2.4928874969482425\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 67872, rl-loss: 6.8016791343688965\n",
      "----------------------------------------\n",
      "  timestep     |  462263\n",
      "  reward       |  1.02175\n",
      "----------------------------------------\n",
      "INFO - Step 68100, rl-loss: 3.1909425258636475\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 69100, rl-loss: 3.3820767402648926\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 69390, rl-loss: 2.0876884460449221\n",
      "----------------------------------------\n",
      "  timestep     |  472808\n",
      "  reward       |  0.937\n",
      "----------------------------------------\n",
      "INFO - Step 70100, rl-loss: 2.3820378780364995\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 70971, rl-loss: 1.4642271995544434\n",
      "----------------------------------------\n",
      "  timestep     |  483380\n",
      "  reward       |  1.01075\n",
      "----------------------------------------\n",
      "INFO - Step 71100, rl-loss: 2.9748120307922363\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 72100, rl-loss: 3.7477104663848877\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 72524, rl-loss: 4.5214681625366216\n",
      "----------------------------------------\n",
      "  timestep     |  493973\n",
      "  reward       |  0.91875\n",
      "----------------------------------------\n",
      "INFO - Step 73100, rl-loss: 4.8062467575073244\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 74100, rl-loss: 3.9302077293395996\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 74136, rl-loss: 3.5324087142944336\n",
      "----------------------------------------\n",
      "  timestep     |  504536\n",
      "  reward       |  0.96725\n",
      "----------------------------------------\n",
      "INFO - Step 75100, rl-loss: 1.7816568613052368\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 75684, rl-loss: 1.92498159408569346\n",
      "----------------------------------------\n",
      "  timestep     |  514997\n",
      "  reward       |  0.99225\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 76100, rl-loss: 3.3157298564910898\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 77100, rl-loss: 2.2169950008392334\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 77167, rl-loss: 1.7377542257308967\n",
      "----------------------------------------\n",
      "  timestep     |  525400\n",
      "  reward       |  0.94925\n",
      "----------------------------------------\n",
      "INFO - Step 78100, rl-loss: 2.7943379878997803\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 78749, rl-loss: 2.3548793792724615\n",
      "----------------------------------------\n",
      "  timestep     |  536039\n",
      "  reward       |  1.0305\n",
      "----------------------------------------\n",
      "INFO - Step 79100, rl-loss: 3.96376609802246124\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 80100, rl-loss: 0.94896930456161553\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 80360, rl-loss: 3.5062856674194336\n",
      "----------------------------------------\n",
      "  timestep     |  546775\n",
      "  reward       |  0.874\n",
      "----------------------------------------\n",
      "INFO - Step 81100, rl-loss: 3.2662708759307865\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 81891, rl-loss: 3.8725419044494634\n",
      "----------------------------------------\n",
      "  timestep     |  557213\n",
      "  reward       |  0.92\n",
      "----------------------------------------\n",
      "INFO - Step 82100, rl-loss: 3.5946683883666996\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 83100, rl-loss: 5.7272458076477056\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 83442, rl-loss: 5.4033694267272956\n",
      "----------------------------------------\n",
      "  timestep     |  567858\n",
      "  reward       |  0.89875\n",
      "----------------------------------------\n",
      "INFO - Step 84100, rl-loss: 3.9299974441528323\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 85007, rl-loss: 3.8434057235717773\n",
      "----------------------------------------\n",
      "  timestep     |  578439\n",
      "  reward       |  0.9745\n",
      "----------------------------------------\n",
      "INFO - Step 85100, rl-loss: 0.8893004059791565\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 86100, rl-loss: 2.5032563209533697\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 86611, rl-loss: 0.6263166666030884\n",
      "----------------------------------------\n",
      "  timestep     |  588943\n",
      "  reward       |  0.94725\n",
      "----------------------------------------\n",
      "INFO - Step 87100, rl-loss: 9.3410530090332037\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 88100, rl-loss: 2.84671783447265624\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 88127, rl-loss: 3.5299232006073137\n",
      "----------------------------------------\n",
      "  timestep     |  599359\n",
      "  reward       |  0.9445\n",
      "----------------------------------------\n",
      "INFO - Step 89100, rl-loss: 2.5818281173706055\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 89668, rl-loss: 6.0730304718017587\n",
      "----------------------------------------\n",
      "  timestep     |  609844\n",
      "  reward       |  0.911\n",
      "----------------------------------------\n",
      "INFO - Step 90100, rl-loss: 4.7440156936645518\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 91100, rl-loss: 3.5152056217193604\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 91203, rl-loss: 2.6441190242767334\n",
      "----------------------------------------\n",
      "  timestep     |  620299\n",
      "  reward       |  0.87675\n",
      "----------------------------------------\n",
      "INFO - Step 92100, rl-loss: 2.9942755699157715\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 92781, rl-loss: 5.2285118103027347\n",
      "----------------------------------------\n",
      "  timestep     |  630888\n",
      "  reward       |  0.9145\n",
      "----------------------------------------\n",
      "INFO - Step 93100, rl-loss: 2.1833057403564453\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 94100, rl-loss: 3.2785551548004155\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 94318, rl-loss: 2.5283746719360353\n",
      "----------------------------------------\n",
      "  timestep     |  641251\n",
      "  reward       |  0.87425\n",
      "----------------------------------------\n",
      "INFO - Step 95100, rl-loss: 1.2876979112625122\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 95884, rl-loss: 3.9361243247985845\n",
      "----------------------------------------\n",
      "  timestep     |  651796\n",
      "  reward       |  1.1275\n",
      "----------------------------------------\n",
      "INFO - Step 96100, rl-loss: 3.8476543426513679\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 97100, rl-loss: 4.9097585678100594\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 97438, rl-loss: 2.1346845626831055\n",
      "----------------------------------------\n",
      "  timestep     |  662370\n",
      "  reward       |  1.07725\n",
      "----------------------------------------\n",
      "INFO - Step 98100, rl-loss: 2.0259397029876713\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 99001, rl-loss: 3.3756008148193363\n",
      "----------------------------------------\n",
      "  timestep     |  672882\n",
      "  reward       |  1.018\n",
      "----------------------------------------\n",
      "INFO - Step 99100, rl-loss: 2.5433564186096197\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 100100, rl-loss: 1.7573336362838745\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 100574, rl-loss: 1.2714998722076416\n",
      "----------------------------------------\n",
      "  timestep     |  683535\n",
      "  reward       |  0.9165\n",
      "----------------------------------------\n",
      "INFO - Step 101100, rl-loss: 2.9956054687536377\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 102092, rl-loss: 4.7033672332763675\n",
      "----------------------------------------\n",
      "  timestep     |  693945\n",
      "  reward       |  0.928\n",
      "----------------------------------------\n",
      "INFO - Step 102100, rl-loss: 1.3066601753234863\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 103100, rl-loss: 4.3791384696960458\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 103639, rl-loss: 2.6696238517761235\n",
      "----------------------------------------\n",
      "  timestep     |  704437\n",
      "  reward       |  1.0305\n",
      "----------------------------------------\n",
      "INFO - Step 104100, rl-loss: 2.0236763954162598\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 105100, rl-loss: 4.7335495948791537\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 105182, rl-loss: 3.0226311683654785\n",
      "----------------------------------------\n",
      "  timestep     |  714962\n",
      "  reward       |  1.00225\n",
      "----------------------------------------\n",
      "INFO - Step 106100, rl-loss: 2.1911733150482178\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 106676, rl-loss: 4.2768249511718752\n",
      "----------------------------------------\n",
      "  timestep     |  725314\n",
      "  reward       |  1.068\n",
      "----------------------------------------\n",
      "INFO - Step 107100, rl-loss: 1.0703985691070557\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 108100, rl-loss: 1.9839770793914795\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 108265, rl-loss: 1.8321807384490967\n",
      "----------------------------------------\n",
      "  timestep     |  736078\n",
      "  reward       |  0.95975\n",
      "----------------------------------------\n",
      "INFO - Step 109100, rl-loss: 1.5117176771163947\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 109827, rl-loss: 6.8012866973876952\n",
      "----------------------------------------\n",
      "  timestep     |  746731\n",
      "  reward       |  1.0175\n",
      "----------------------------------------\n",
      "INFO - Step 110100, rl-loss: 1.9626158475875854\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 111100, rl-loss: 2.3256344795227055\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 111313, rl-loss: 1.1765239238739014\n",
      "----------------------------------------\n",
      "  timestep     |  757132\n",
      "  reward       |  1.03175\n",
      "----------------------------------------\n",
      "INFO - Step 112100, rl-loss: 3.2726407051086426\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 112862, rl-loss: 5.7193269729614264\n",
      "----------------------------------------\n",
      "  timestep     |  767560\n",
      "  reward       |  1.044\n",
      "----------------------------------------\n",
      "INFO - Step 113100, rl-loss: 1.3488143682479858\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 114100, rl-loss: 2.0603008270263677\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 114397, rl-loss: 2.1503229141235355\n",
      "----------------------------------------\n",
      "  timestep     |  778085\n",
      "  reward       |  1.1105\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 115100, rl-loss: 3.7957315444946295\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 115950, rl-loss: 1.17614245414733895\n",
      "----------------------------------------\n",
      "  timestep     |  788448\n",
      "  reward       |  0.96675\n",
      "----------------------------------------\n",
      "INFO - Step 116100, rl-loss: 2.5411086082458496\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 117100, rl-loss: 3.3113503456115723\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 117508, rl-loss: 3.3526988029479985\n",
      "----------------------------------------\n",
      "  timestep     |  799000\n",
      "  reward       |  0.977\n",
      "----------------------------------------\n",
      "INFO - Step 118100, rl-loss: 5.2198276519775394\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 119048, rl-loss: 7.8175115585327155\n",
      "----------------------------------------\n",
      "  timestep     |  809407\n",
      "  reward       |  1.05825\n",
      "----------------------------------------\n",
      "INFO - Step 119100, rl-loss: 3.2572436332702637\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 120100, rl-loss: 3.3346886634826661\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 120650, rl-loss: 3.2512879371643066\n",
      "----------------------------------------\n",
      "  timestep     |  820034\n",
      "  reward       |  1.053\n",
      "----------------------------------------\n",
      "INFO - Step 121100, rl-loss: 4.91487789154052765\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 122100, rl-loss: 5.3743114471435557\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 122276, rl-loss: 3.9883875846862793\n",
      "----------------------------------------\n",
      "  timestep     |  830672\n",
      "  reward       |  1.022\n",
      "----------------------------------------\n",
      "INFO - Step 123100, rl-loss: 5.02404212951660235\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 123845, rl-loss: 1.92780303955078127\n",
      "----------------------------------------\n",
      "  timestep     |  841292\n",
      "  reward       |  1.00475\n",
      "----------------------------------------\n",
      "INFO - Step 124100, rl-loss: 2.1632673740386963\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 125100, rl-loss: 3.5178298950195312\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 125457, rl-loss: 1.3658916950225837\n",
      "----------------------------------------\n",
      "  timestep     |  851808\n",
      "  reward       |  0.9995\n",
      "----------------------------------------\n",
      "INFO - Step 126100, rl-loss: 2.5282797813415527\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 127013, rl-loss: 5.7410922050476076\n",
      "----------------------------------------\n",
      "  timestep     |  862279\n",
      "  reward       |  1.04075\n",
      "----------------------------------------\n",
      "INFO - Step 127100, rl-loss: 2.0014765262603765\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 128100, rl-loss: 4.51049280166626753\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 128608, rl-loss: 4.88378047943115256\n",
      "----------------------------------------\n",
      "  timestep     |  872721\n",
      "  reward       |  0.923\n",
      "----------------------------------------\n",
      "INFO - Step 129100, rl-loss: 4.1903896331787111\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 130100, rl-loss: 2.7796454429626465\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 130192, rl-loss: 1.6708350181579597\n",
      "----------------------------------------\n",
      "  timestep     |  883357\n",
      "  reward       |  1.08225\n",
      "----------------------------------------\n",
      "INFO - Step 131100, rl-loss: 3.9237215518951416\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 131780, rl-loss: 3.1090269088745117\n",
      "----------------------------------------\n",
      "  timestep     |  894165\n",
      "  reward       |  1.01825\n",
      "----------------------------------------\n",
      "INFO - Step 132100, rl-loss: 3.9675154685974123\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 133100, rl-loss: 3.7572073936462402\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 133370, rl-loss: 3.8420612812042236\n",
      "----------------------------------------\n",
      "  timestep     |  904745\n",
      "  reward       |  1.1165\n",
      "----------------------------------------\n",
      "INFO - Step 134100, rl-loss: 2.8110556602478027\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 134919, rl-loss: 2.3027641773223877\n",
      "----------------------------------------\n",
      "  timestep     |  915300\n",
      "  reward       |  1.07575\n",
      "----------------------------------------\n",
      "INFO - Step 135100, rl-loss: 3.5233530998229986\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 136100, rl-loss: 2.8570866584777835\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 136413, rl-loss: 3.2767567634582524\n",
      "----------------------------------------\n",
      "  timestep     |  925903\n",
      "  reward       |  0.88775\n",
      "----------------------------------------\n",
      "INFO - Step 137100, rl-loss: 3.2489809989929213\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 137960, rl-loss: 4.4393930435180663\n",
      "----------------------------------------\n",
      "  timestep     |  936349\n",
      "  reward       |  0.9595\n",
      "----------------------------------------\n",
      "INFO - Step 138100, rl-loss: 4.5463023185729985\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 139100, rl-loss: 3.8616454601287845\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 139516, rl-loss: 2.4875028133392334\n",
      "----------------------------------------\n",
      "  timestep     |  946807\n",
      "  reward       |  1.00025\n",
      "----------------------------------------\n",
      "INFO - Step 140100, rl-loss: 3.9730374813079834\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 141100, rl-loss: 2.4880728721618652\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 141118, rl-loss: 2.8670206069946293\n",
      "----------------------------------------\n",
      "  timestep     |  957401\n",
      "  reward       |  0.925\n",
      "----------------------------------------\n",
      "INFO - Step 142100, rl-loss: 7.4107747077941895\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 142655, rl-loss: 4.0862650871276855\n",
      "----------------------------------------\n",
      "  timestep     |  967930\n",
      "  reward       |  1.055\n",
      "----------------------------------------\n",
      "INFO - Step 143100, rl-loss: 2.9398598670959473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 144100, rl-loss: 3.7245225906372074\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 144252, rl-loss: 1.8033939599990845\n",
      "----------------------------------------\n",
      "  timestep     |  978501\n",
      "  reward       |  0.982\n",
      "----------------------------------------\n",
      "INFO - Step 145100, rl-loss: 2.3635115623474124\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 145768, rl-loss: 3.2286133766174316\n",
      "----------------------------------------\n",
      "  timestep     |  988994\n",
      "  reward       |  0.91925\n",
      "----------------------------------------\n",
      "INFO - Step 146100, rl-loss: 2.5010585784912115\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 147100, rl-loss: 1.7645254135131836\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 147308, rl-loss: 4.9451217651367195\n",
      "----------------------------------------\n",
      "  timestep     |  999450\n",
      "  reward       |  0.98825\n",
      "----------------------------------------\n",
      "INFO - Step 148100, rl-loss: 1.1366397142410278\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 148885, rl-loss: 5.4514198303222668\n",
      "----------------------------------------\n",
      "  timestep     |  1010055\n",
      "  reward       |  0.94775\n",
      "----------------------------------------\n",
      "INFO - Step 149100, rl-loss: 3.7319226264953613\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 150100, rl-loss: 2.1383137702941895\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 150465, rl-loss: 4.8935461044311527\n",
      "----------------------------------------\n",
      "  timestep     |  1020606\n",
      "  reward       |  1.05575\n",
      "----------------------------------------\n",
      "INFO - Step 151100, rl-loss: 2.3900897502899176\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 151999, rl-loss: 4.1288499832153325\n",
      "----------------------------------------\n",
      "  timestep     |  1031099\n",
      "  reward       |  1.1025\n",
      "----------------------------------------\n",
      "INFO - Step 152100, rl-loss: 1.2910592555999756\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 153100, rl-loss: 3.3060178756713867\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 153560, rl-loss: 2.7967519760131836\n",
      "----------------------------------------\n",
      "  timestep     |  1041680\n",
      "  reward       |  1.04475\n",
      "----------------------------------------\n",
      "INFO - Step 154100, rl-loss: 1.9043855667114258\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 155072, rl-loss: 4.5325589179992684\n",
      "----------------------------------------\n",
      "  timestep     |  1052243\n",
      "  reward       |  1.03975\n",
      "----------------------------------------\n",
      "INFO - Step 155100, rl-loss: 2.1069285869598395\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 156100, rl-loss: 1.8120903968811035\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 156633, rl-loss: 1.2900323867797852\n",
      "----------------------------------------\n",
      "  timestep     |  1062793\n",
      "  reward       |  0.9625\n",
      "----------------------------------------\n",
      "INFO - Step 157100, rl-loss: 3.7803270816802984\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 158100, rl-loss: 6.7206115722656251\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 158225, rl-loss: 3.9793055057525635\n",
      "----------------------------------------\n",
      "  timestep     |  1073335\n",
      "  reward       |  0.927\n",
      "----------------------------------------\n",
      "INFO - Step 159100, rl-loss: 2.35224890708923344\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 159799, rl-loss: 2.3477582931518555\n",
      "----------------------------------------\n",
      "  timestep     |  1083946\n",
      "  reward       |  0.9495\n",
      "----------------------------------------\n",
      "INFO - Step 160100, rl-loss: 1.5946841239929262\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 161100, rl-loss: 1.5514202117919922\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 161360, rl-loss: 3.5780591964721685\n",
      "----------------------------------------\n",
      "  timestep     |  1094478\n",
      "  reward       |  1.02825\n",
      "----------------------------------------\n",
      "INFO - Step 162100, rl-loss: 3.0455679893493652\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 162967, rl-loss: 5.6319084167480476\n",
      "----------------------------------------\n",
      "  timestep     |  1105196\n",
      "  reward       |  0.98225\n",
      "----------------------------------------\n",
      "INFO - Step 163100, rl-loss: 1.7299112081527718\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 164100, rl-loss: 2.1001324653625498\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 164532, rl-loss: 1.2480052709579468\n",
      "----------------------------------------\n",
      "  timestep     |  1115811\n",
      "  reward       |  1.06725\n",
      "----------------------------------------\n",
      "INFO - Step 165100, rl-loss: 1.6759428977966309\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 166100, rl-loss: 2.4525616168975837\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 166133, rl-loss: 1.2157477140426636\n",
      "----------------------------------------\n",
      "  timestep     |  1126398\n",
      "  reward       |  0.98475\n",
      "----------------------------------------\n",
      "INFO - Step 167100, rl-loss: 3.0443582534790048\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 167676, rl-loss: 4.6095371246337898\n",
      "----------------------------------------\n",
      "  timestep     |  1136973\n",
      "  reward       |  0.991\n",
      "----------------------------------------\n",
      "INFO - Step 168100, rl-loss: 2.7559747695922853\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 169100, rl-loss: 4.4286384582519536\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 169226, rl-loss: 1.4538211822509766\n",
      "----------------------------------------\n",
      "  timestep     |  1147497\n",
      "  reward       |  1.01225\n",
      "----------------------------------------\n",
      "INFO - Step 170100, rl-loss: 2.5366911888122562\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 170723, rl-loss: 3.6869969367980957\n",
      "----------------------------------------\n",
      "  timestep     |  1157904\n",
      "  reward       |  0.92775\n",
      "----------------------------------------\n",
      "INFO - Step 171100, rl-loss: 4.5725288391113288\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 172100, rl-loss: 3.8061177730560303\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 172230, rl-loss: 2.9092538356781006\n",
      "----------------------------------------\n",
      "  timestep     |  1168422\n",
      "  reward       |  0.98925\n",
      "----------------------------------------\n",
      "INFO - Step 173100, rl-loss: 3.7521111965179443\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 173764, rl-loss: 5.2025532722473145\n",
      "----------------------------------------\n",
      "  timestep     |  1178908\n",
      "  reward       |  1.01425\n",
      "----------------------------------------\n",
      "INFO - Step 174100, rl-loss: 1.8674960136413574\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 175100, rl-loss: 2.2417807579040527\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 175290, rl-loss: 2.9408907890319824\n",
      "----------------------------------------\n",
      "  timestep     |  1189435\n",
      "  reward       |  0.951\n",
      "----------------------------------------\n",
      "INFO - Step 176100, rl-loss: 2.7746191024780273\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 176852, rl-loss: 1.7246884107589722\n",
      "----------------------------------------\n",
      "  timestep     |  1200001\n",
      "  reward       |  1.017\n",
      "----------------------------------------\n",
      "INFO - Step 177100, rl-loss: 2.3551242351531982\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 178100, rl-loss: 2.92329335212707576\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 178370, rl-loss: 1.3073233366012573\n",
      "----------------------------------------\n",
      "  timestep     |  1210413\n",
      "  reward       |  0.89675\n",
      "----------------------------------------\n",
      "INFO - Step 179100, rl-loss: 3.5189194679260254\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 179906, rl-loss: 4.0662460327148446\n",
      "----------------------------------------\n",
      "  timestep     |  1220830\n",
      "  reward       |  0.9885\n",
      "----------------------------------------\n",
      "INFO - Step 180100, rl-loss: 1.7510817050933838\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 181100, rl-loss: 4.0918321609497075\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 181442, rl-loss: 3.0433104038238525\n",
      "----------------------------------------\n",
      "  timestep     |  1231428\n",
      "  reward       |  1.06525\n",
      "----------------------------------------\n",
      "INFO - Step 182100, rl-loss: 2.7247781753540043\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 183028, rl-loss: 1.2969095706939697\n",
      "----------------------------------------\n",
      "  timestep     |  1242117\n",
      "  reward       |  0.98375\n",
      "----------------------------------------\n",
      "INFO - Step 183100, rl-loss: 4.6635608673095734\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 184100, rl-loss: 1.2255618572235107\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 184601, rl-loss: 4.8657298088073735\n",
      "----------------------------------------\n",
      "  timestep     |  1252736\n",
      "  reward       |  1.0345\n",
      "----------------------------------------\n",
      "INFO - Step 185100, rl-loss: 2.7290070056915283\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 186100, rl-loss: 1.6989917755126953\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 186177, rl-loss: 6.8855786323547366\n",
      "----------------------------------------\n",
      "  timestep     |  1263143\n",
      "  reward       |  1.0335\n",
      "----------------------------------------\n",
      "INFO - Step 187100, rl-loss: 1.4941987991333008\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 187725, rl-loss: 2.3503150939941406\n",
      "----------------------------------------\n",
      "  timestep     |  1273735\n",
      "  reward       |  0.9205\n",
      "----------------------------------------\n",
      "INFO - Step 188100, rl-loss: 4.0668239593505864\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 189100, rl-loss: 1.88279020786285416\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 189289, rl-loss: 5.5926804542541525\n",
      "----------------------------------------\n",
      "  timestep     |  1284306\n",
      "  reward       |  0.95125\n",
      "----------------------------------------\n",
      "INFO - Step 190100, rl-loss: 3.9380745887756348\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 190813, rl-loss: 2.6037540435791016\n",
      "----------------------------------------\n",
      "  timestep     |  1294809\n",
      "  reward       |  1.0385\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 191100, rl-loss: 2.9437980651855476\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 192100, rl-loss: 3.0911478996276855\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 192387, rl-loss: 1.7093067169189453\n",
      "----------------------------------------\n",
      "  timestep     |  1305373\n",
      "  reward       |  0.89175\n",
      "----------------------------------------\n",
      "INFO - Step 193100, rl-loss: 0.8674354553222656\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 193935, rl-loss: 2.9858970642089844\n",
      "----------------------------------------\n",
      "  timestep     |  1315839\n",
      "  reward       |  1.0015\n",
      "----------------------------------------\n",
      "INFO - Step 194100, rl-loss: 4.16415786743164154\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 195100, rl-loss: 2.8712935447692877\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 195494, rl-loss: 1.99725508689880375\n",
      "----------------------------------------\n",
      "  timestep     |  1326303\n",
      "  reward       |  1.0325\n",
      "----------------------------------------\n",
      "INFO - Step 196100, rl-loss: 1.7528542280197144\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 196998, rl-loss: 2.3482396602630615\n",
      "----------------------------------------\n",
      "  timestep     |  1336808\n",
      "  reward       |  1.0615\n",
      "----------------------------------------\n",
      "INFO - Step 197100, rl-loss: 5.7105622291564945\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 198100, rl-loss: 2.6962981224060066\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 198645, rl-loss: 1.5337915420532227\n",
      "----------------------------------------\n",
      "  timestep     |  1347432\n",
      "  reward       |  1.09475\n",
      "----------------------------------------\n",
      "INFO - Step 199100, rl-loss: 2.5351703166961678\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 200100, rl-loss: 4.10582780838012746\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 200234, rl-loss: 3.0860679149627686\n",
      "----------------------------------------\n",
      "  timestep     |  1357996\n",
      "  reward       |  0.99825\n",
      "----------------------------------------\n",
      "INFO - Step 201100, rl-loss: 4.3037853240966883\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 201787, rl-loss: 3.1384770870208746\n",
      "----------------------------------------\n",
      "  timestep     |  1368508\n",
      "  reward       |  0.94575\n",
      "----------------------------------------\n",
      "INFO - Step 202100, rl-loss: 2.1556708812713623\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 203100, rl-loss: 3.7473106384277344\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 203364, rl-loss: 2.5415167808532715\n",
      "----------------------------------------\n",
      "  timestep     |  1379080\n",
      "  reward       |  1.0725\n",
      "----------------------------------------\n",
      "INFO - Step 204100, rl-loss: 4.6692714691162117\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 204955, rl-loss: 4.7195949554443368\n",
      "----------------------------------------\n",
      "  timestep     |  1389756\n",
      "  reward       |  1.043\n",
      "----------------------------------------\n",
      "INFO - Step 205100, rl-loss: 2.5722725391387945\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 206100, rl-loss: 4.0434613227844245\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 206538, rl-loss: 2.2561175823211675\n",
      "----------------------------------------\n",
      "  timestep     |  1400369\n",
      "  reward       |  0.97775\n",
      "----------------------------------------\n",
      "INFO - Step 207100, rl-loss: 2.1049962043762207\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 208071, rl-loss: 3.5094606876373294\n",
      "----------------------------------------\n",
      "  timestep     |  1410841\n",
      "  reward       |  0.98825\n",
      "----------------------------------------\n",
      "INFO - Step 208100, rl-loss: 2.7146844863891684\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 209100, rl-loss: 6.11705350875854526\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 209628, rl-loss: 1.8492019176483154\n",
      "----------------------------------------\n",
      "  timestep     |  1421329\n",
      "  reward       |  1.0535\n",
      "----------------------------------------\n",
      "INFO - Step 210100, rl-loss: 2.0362987518310547\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 211100, rl-loss: 3.6587762832641665\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 211195, rl-loss: 1.6598396301269531\n",
      "----------------------------------------\n",
      "  timestep     |  1431864\n",
      "  reward       |  1.01175\n",
      "----------------------------------------\n",
      "INFO - Step 212100, rl-loss: 6.6979608535766655\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 212735, rl-loss: 2.1891181468963623\n",
      "----------------------------------------\n",
      "  timestep     |  1442373\n",
      "  reward       |  1.08375\n",
      "----------------------------------------\n",
      "INFO - Step 213100, rl-loss: 1.9729714393615723\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 214100, rl-loss: 5.8813743591308593\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 214276, rl-loss: 2.4373748302459717\n",
      "----------------------------------------\n",
      "  timestep     |  1452795\n",
      "  reward       |  0.97\n",
      "----------------------------------------\n",
      "INFO - Step 215100, rl-loss: 4.22657394409179753\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 215835, rl-loss: 1.7208163738250732\n",
      "----------------------------------------\n",
      "  timestep     |  1463327\n",
      "  reward       |  1.0125\n",
      "----------------------------------------\n",
      "INFO - Step 216100, rl-loss: 2.3996145725250244\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 217100, rl-loss: 1.6282110214233398\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 217386, rl-loss: 2.12722015380859383\n",
      "----------------------------------------\n",
      "  timestep     |  1473886\n",
      "  reward       |  1.04775\n",
      "----------------------------------------\n",
      "INFO - Step 218100, rl-loss: 3.3800563812255865\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 218921, rl-loss: 2.1644370555877686\n",
      "----------------------------------------\n",
      "  timestep     |  1484429\n",
      "  reward       |  1.00625\n",
      "----------------------------------------\n",
      "INFO - Step 219100, rl-loss: 3.2462677955627442\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 220100, rl-loss: 6.0945253372192381\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 220504, rl-loss: 1.5318783521652222\n",
      "----------------------------------------\n",
      "  timestep     |  1494917\n",
      "  reward       |  1.01625\n",
      "----------------------------------------\n",
      "INFO - Step 221100, rl-loss: 3.2203249931335453\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 222024, rl-loss: 4.8382468223571784\n",
      "----------------------------------------\n",
      "  timestep     |  1505395\n",
      "  reward       |  1.07675\n",
      "----------------------------------------\n",
      "INFO - Step 222100, rl-loss: 6.2255573272705087\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 223100, rl-loss: 1.7959740161895752\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 223554, rl-loss: 4.1942620277404785\n",
      "----------------------------------------\n",
      "  timestep     |  1515841\n",
      "  reward       |  1.0235\n",
      "----------------------------------------\n",
      "INFO - Step 224100, rl-loss: 4.2812523841857915\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 225071, rl-loss: 2.6214699745178223\n",
      "----------------------------------------\n",
      "  timestep     |  1526274\n",
      "  reward       |  1.0655\n",
      "----------------------------------------\n",
      "INFO - Step 225100, rl-loss: 5.6868400573730475\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 226100, rl-loss: 1.9758437871932983\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 226627, rl-loss: 4.4459471702575684\n",
      "----------------------------------------\n",
      "  timestep     |  1536888\n",
      "  reward       |  1.08675\n",
      "----------------------------------------\n",
      "INFO - Step 227100, rl-loss: 4.0974788665771484\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 228100, rl-loss: 3.5597701072692878\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 228226, rl-loss: 1.6457899808883667\n",
      "----------------------------------------\n",
      "  timestep     |  1547579\n",
      "  reward       |  1.14075\n",
      "----------------------------------------\n",
      "INFO - Step 229100, rl-loss: 3.0016951560974125\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 229779, rl-loss: 6.3847341537475598\n",
      "----------------------------------------\n",
      "  timestep     |  1557943\n",
      "  reward       |  1.0705\n",
      "----------------------------------------\n",
      "INFO - Step 230100, rl-loss: 4.3533034324646445\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 231100, rl-loss: 2.9086804389953613\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 231366, rl-loss: 1.8175606727600098\n",
      "----------------------------------------\n",
      "  timestep     |  1568440\n",
      "  reward       |  1.091\n",
      "----------------------------------------\n",
      "INFO - Step 232100, rl-loss: 5.3727207183837892\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 232893, rl-loss: 4.3252482414245605\n",
      "----------------------------------------\n",
      "  timestep     |  1578871\n",
      "  reward       |  1.12975\n",
      "----------------------------------------\n",
      "INFO - Step 233100, rl-loss: 2.4580934047698975\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 234100, rl-loss: 6.6709899902343757\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 234487, rl-loss: 2.0455799102783203\n",
      "----------------------------------------\n",
      "  timestep     |  1589501\n",
      "  reward       |  1.1215\n",
      "----------------------------------------\n",
      "INFO - Step 235100, rl-loss: 2.50027728080749555\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 236037, rl-loss: 2.2882790565490723\n",
      "----------------------------------------\n",
      "  timestep     |  1600056\n",
      "  reward       |  0.99375\n",
      "----------------------------------------\n",
      "INFO - Step 236100, rl-loss: 4.5588693618774415\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 237100, rl-loss: 2.6429526805877686\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 237589, rl-loss: 2.0446627140045166\n",
      "----------------------------------------\n",
      "  timestep     |  1610662\n",
      "  reward       |  1.11475\n",
      "----------------------------------------\n",
      "INFO - Step 238100, rl-loss: 2.8197917938232426\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 239100, rl-loss: 3.4535140991210938\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 239127, rl-loss: 2.1428208351135254\n",
      "----------------------------------------\n",
      "  timestep     |  1621178\n",
      "  reward       |  1.0855\n",
      "----------------------------------------\n",
      "INFO - Step 240100, rl-loss: 2.9147973060607913\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 240661, rl-loss: 4.8609099388122565\n",
      "----------------------------------------\n",
      "  timestep     |  1631654\n",
      "  reward       |  1.101\n",
      "----------------------------------------\n",
      "INFO - Step 241100, rl-loss: 2.3424236774444584\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 242100, rl-loss: 1.1554207801818848\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 242231, rl-loss: 2.7389211654663086\n",
      "----------------------------------------\n",
      "  timestep     |  1642442\n",
      "  reward       |  1.00475\n",
      "----------------------------------------\n",
      "INFO - Step 243100, rl-loss: 1.86857652664184576\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 243783, rl-loss: 1.9667333364486694\n",
      "----------------------------------------\n",
      "  timestep     |  1653021\n",
      "  reward       |  1.07975\n",
      "----------------------------------------\n",
      "INFO - Step 244100, rl-loss: 4.1306657791137695\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 245100, rl-loss: 1.3345788717269897\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 245290, rl-loss: 4.1557221412658697\n",
      "----------------------------------------\n",
      "  timestep     |  1663343\n",
      "  reward       |  1.08025\n",
      "----------------------------------------\n",
      "INFO - Step 246100, rl-loss: 2.3013334274291992\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 246821, rl-loss: 2.8310697078704834\n",
      "----------------------------------------\n",
      "  timestep     |  1673719\n",
      "  reward       |  1.134\n",
      "----------------------------------------\n",
      "INFO - Step 247100, rl-loss: 2.0239629745483412\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 248100, rl-loss: 2.6598985195159915\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 248372, rl-loss: 2.3411853313446045\n",
      "----------------------------------------\n",
      "  timestep     |  1684263\n",
      "  reward       |  1.0125\n",
      "----------------------------------------\n",
      "INFO - Step 249100, rl-loss: 2.4559812545776367\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 249879, rl-loss: 3.4188928604125977\n",
      "----------------------------------------\n",
      "  timestep     |  1694649\n",
      "  reward       |  1.06625\n",
      "----------------------------------------\n",
      "INFO - Step 250100, rl-loss: 3.9991199970245364\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 251100, rl-loss: 4.8472251892089841\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 251413, rl-loss: 2.5825138092041016\n",
      "----------------------------------------\n",
      "  timestep     |  1705152\n",
      "  reward       |  1.06575\n",
      "----------------------------------------\n",
      "INFO - Step 252100, rl-loss: 1.9983479976654053\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 252978, rl-loss: 2.0415041446685795\n",
      "----------------------------------------\n",
      "  timestep     |  1715625\n",
      "  reward       |  0.9015\n",
      "----------------------------------------\n",
      "INFO - Step 253100, rl-loss: 2.3681535720825195\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 254100, rl-loss: 1.6162383556365967\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 254533, rl-loss: 1.0985186100006104\n",
      "----------------------------------------\n",
      "  timestep     |  1726214\n",
      "  reward       |  1.00875\n",
      "----------------------------------------\n",
      "INFO - Step 255100, rl-loss: 5.5152583122253426\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 256067, rl-loss: 1.2770521640777588\n",
      "----------------------------------------\n",
      "  timestep     |  1736825\n",
      "  reward       |  0.987\n",
      "----------------------------------------\n",
      "INFO - Step 256100, rl-loss: 2.2635486125946045\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 257100, rl-loss: 3.0817329883575447\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 257638, rl-loss: 1.6563936471939087\n",
      "----------------------------------------\n",
      "  timestep     |  1747337\n",
      "  reward       |  1.041\n",
      "----------------------------------------\n",
      "INFO - Step 258100, rl-loss: 2.9547982215881348\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 259100, rl-loss: 1.2945115566253662\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 259186, rl-loss: 5.2108354568481445\n",
      "----------------------------------------\n",
      "  timestep     |  1757762\n",
      "  reward       |  0.994\n",
      "----------------------------------------\n",
      "INFO - Step 260100, rl-loss: 4.4786381721496586\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 260724, rl-loss: 2.9216160774230957\n",
      "----------------------------------------\n",
      "  timestep     |  1768282\n",
      "  reward       |  1.046\n",
      "----------------------------------------\n",
      "INFO - Step 261100, rl-loss: 3.9691567420959473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 262100, rl-loss: 6.1436424255371095\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 262267, rl-loss: 1.2692749500274658\n",
      "----------------------------------------\n",
      "  timestep     |  1778694\n",
      "  reward       |  1.04125\n",
      "----------------------------------------\n",
      "INFO - Step 263100, rl-loss: 2.8196060657501226\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 263841, rl-loss: 2.9233679771423346\n",
      "----------------------------------------\n",
      "  timestep     |  1789147\n",
      "  reward       |  1.111\n",
      "----------------------------------------\n",
      "INFO - Step 264100, rl-loss: 3.2137374877929688\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 265100, rl-loss: 1.4467128515243532\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 265398, rl-loss: 3.3861818313598633\n",
      "----------------------------------------\n",
      "  timestep     |  1799715\n",
      "  reward       |  1.09\n",
      "----------------------------------------\n",
      "INFO - Step 266100, rl-loss: 4.0524830818176274\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 266930, rl-loss: 2.7685599327087402\n",
      "----------------------------------------\n",
      "  timestep     |  1810134\n",
      "  reward       |  1.179\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 267100, rl-loss: 2.8190014362335205\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 268100, rl-loss: 1.38651299476623547\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 268510, rl-loss: 3.4914007186889657\n",
      "----------------------------------------\n",
      "  timestep     |  1820695\n",
      "  reward       |  1.0575\n",
      "----------------------------------------\n",
      "INFO - Step 269100, rl-loss: 0.8058529496192932\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 270023, rl-loss: 1.8320597410202026\n",
      "----------------------------------------\n",
      "  timestep     |  1831084\n",
      "  reward       |  1.178\n",
      "----------------------------------------\n",
      "INFO - Step 270100, rl-loss: 1.7283072471618652\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 271100, rl-loss: 4.5882587432861335\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 271625, rl-loss: 1.9744039773941046\n",
      "----------------------------------------\n",
      "  timestep     |  1841756\n",
      "  reward       |  1.06275\n",
      "----------------------------------------\n",
      "INFO - Step 272100, rl-loss: 2.8667163848876953\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 273100, rl-loss: 1.8169764280319214\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 273147, rl-loss: 1.6508542299270634\n",
      "----------------------------------------\n",
      "  timestep     |  1852235\n",
      "  reward       |  1.11\n",
      "----------------------------------------\n",
      "INFO - Step 274100, rl-loss: 2.33200311660766674\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 274709, rl-loss: 2.6639101505279547\n",
      "----------------------------------------\n",
      "  timestep     |  1862784\n",
      "  reward       |  0.98225\n",
      "----------------------------------------\n",
      "INFO - Step 275100, rl-loss: 4.2225217819213874\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 276100, rl-loss: 2.5724825859069824\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 276307, rl-loss: 2.1717431545257572\n",
      "----------------------------------------\n",
      "  timestep     |  1873302\n",
      "  reward       |  1.17\n",
      "----------------------------------------\n",
      "INFO - Step 277100, rl-loss: 2.1000337600708016\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 277869, rl-loss: 3.7665548324584967\n",
      "----------------------------------------\n",
      "  timestep     |  1883739\n",
      "  reward       |  1.006\n",
      "----------------------------------------\n",
      "INFO - Step 278100, rl-loss: 2.3618216514587402\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 279100, rl-loss: 2.2958698272705086\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 279443, rl-loss: 2.1937117576599124\n",
      "----------------------------------------\n",
      "  timestep     |  1894274\n",
      "  reward       |  0.99525\n",
      "----------------------------------------\n",
      "INFO - Step 280100, rl-loss: 2.8272469043731697\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 280965, rl-loss: 1.4139449596405036\n",
      "----------------------------------------\n",
      "  timestep     |  1904830\n",
      "  reward       |  1.14325\n",
      "----------------------------------------\n",
      "INFO - Step 281100, rl-loss: 3.5096538066864014\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 282100, rl-loss: 4.6266713142395028\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 282531, rl-loss: 2.20773839950561526\n",
      "----------------------------------------\n",
      "  timestep     |  1915359\n",
      "  reward       |  1.1375\n",
      "----------------------------------------\n",
      "INFO - Step 283100, rl-loss: 2.7448389530181885\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 284100, rl-loss: 2.3875019550323486\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 284140, rl-loss: 3.9015986919403076\n",
      "----------------------------------------\n",
      "  timestep     |  1926138\n",
      "  reward       |  1.08225\n",
      "----------------------------------------\n",
      "INFO - Step 285100, rl-loss: 3.1908130645751953\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 285775, rl-loss: 2.8163480758666996\n",
      "----------------------------------------\n",
      "  timestep     |  1936857\n",
      "  reward       |  1.003\n",
      "----------------------------------------\n",
      "INFO - Step 286100, rl-loss: 3.7984085083007812\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 287100, rl-loss: 5.8414773941040043\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 287340, rl-loss: 2.8978276252746584\n",
      "----------------------------------------\n",
      "  timestep     |  1947434\n",
      "  reward       |  1.127\n",
      "----------------------------------------\n",
      "INFO - Step 288100, rl-loss: 4.8246021270751955\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 288901, rl-loss: 3.5429298877716064\n",
      "----------------------------------------\n",
      "  timestep     |  1958010\n",
      "  reward       |  0.9695\n",
      "----------------------------------------\n",
      "INFO - Step 289100, rl-loss: 2.0528345108032227\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 290100, rl-loss: 2.2369170188903819\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 290472, rl-loss: 5.5476188659667972\n",
      "----------------------------------------\n",
      "  timestep     |  1968491\n",
      "  reward       |  1.0275\n",
      "----------------------------------------\n",
      "INFO - Step 291100, rl-loss: 2.4521586894989014\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 292000, rl-loss: 3.1490640640258797\n",
      "----------------------------------------\n",
      "  timestep     |  1979033\n",
      "  reward       |  1.157\n",
      "----------------------------------------\n",
      "INFO - Step 292100, rl-loss: 4.0014505386352547\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 293100, rl-loss: 4.4776816368103032\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 293608, rl-loss: 4.5359630584716863\n",
      "----------------------------------------\n",
      "  timestep     |  1989622\n",
      "  reward       |  0.98825\n",
      "----------------------------------------\n",
      "INFO - Step 294100, rl-loss: 6.3970746994018555\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 295100, rl-loss: 1.6183719635009766\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 295139, rl-loss: 4.5189924240112305\n",
      "----------------------------------------\n",
      "  timestep     |  2000251\n",
      "  reward       |  1.134\n",
      "----------------------------------------\n",
      "INFO - Step 296100, rl-loss: 3.8237357139587402\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 296642, rl-loss: 2.5110688209533695\n",
      "----------------------------------------\n",
      "  timestep     |  2010622\n",
      "  reward       |  1.08525\n",
      "----------------------------------------\n",
      "INFO - Step 297100, rl-loss: 3.8923835754394534\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 298100, rl-loss: 4.6115713119506843\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 298121, rl-loss: 2.5656919479370117\n",
      "----------------------------------------\n",
      "  timestep     |  2020936\n",
      "  reward       |  1.09925\n",
      "----------------------------------------\n",
      "INFO - Step 299100, rl-loss: 4.82091569900512736\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 299654, rl-loss: 2.5598130226135254\n",
      "----------------------------------------\n",
      "  timestep     |  2031373\n",
      "  reward       |  0.9885\n",
      "----------------------------------------\n",
      "INFO - Step 300100, rl-loss: 1.0983755588531494\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 301100, rl-loss: 2.9761428833007812\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 301200, rl-loss: 5.4608130455017093\n",
      "----------------------------------------\n",
      "  timestep     |  2042021\n",
      "  reward       |  1.058\n",
      "----------------------------------------\n",
      "INFO - Step 302100, rl-loss: 2.2084500789642334\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 302795, rl-loss: 1.12093114852905273\n",
      "----------------------------------------\n",
      "  timestep     |  2052654\n",
      "  reward       |  1.02575\n",
      "----------------------------------------\n",
      "INFO - Step 303100, rl-loss: 3.4776906967163086\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 304100, rl-loss: 5.7957224845886236\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 304405, rl-loss: 2.9292769432067877\n",
      "----------------------------------------\n",
      "  timestep     |  2063245\n",
      "  reward       |  1.001\n",
      "----------------------------------------\n",
      "INFO - Step 305100, rl-loss: 2.5958795547485352\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 305918, rl-loss: 2.7649865150451665\n",
      "----------------------------------------\n",
      "  timestep     |  2073626\n",
      "  reward       |  1.0485\n",
      "----------------------------------------\n",
      "INFO - Step 306100, rl-loss: 3.5755875110626227\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 307100, rl-loss: 1.87759375572204664\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 307495, rl-loss: 1.7173893451690674\n",
      "----------------------------------------\n",
      "  timestep     |  2084197\n",
      "  reward       |  1.0835\n",
      "----------------------------------------\n",
      "INFO - Step 308100, rl-loss: 2.5976221561431885\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 309031, rl-loss: 4.5996346473693859\n",
      "Logs saved in ./leduc-nfsp\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = get_device()\n",
    "# from rlcard.agents import NFSPAgent\n",
    "\n",
    "env = rlcard.make(GAME, config={'seed': 0})\n",
    "\n",
    "nfsp = NFSPAgent(env, device)\n",
    "nfsp.eta = 0.9\n",
    "# nfsp = NFSPAgent(num_actions=env.num_actions,\n",
    "#                           state_shape=env.state_shape[0],\n",
    "#                           hidden_layers_sizes=[64,64],\n",
    "#                           q_mlp_layers=[64,64],\n",
    "#                           device=device)\n",
    "\n",
    "env.set_agents([nfsp, RandomAgent(num_actions=env.num_actions)])\n",
    "\n",
    "# one episode\n",
    "sl_loss = []\n",
    "with Logger('./leduc-nfsp') as logger:\n",
    "    for i in range(EPISODES):\n",
    "        trajectories, payoffs = env.run(is_training=True) # requires a step method. Will populate the transition buffer m_sl\n",
    "        trajectories = reorganize(trajectories, payoffs)\n",
    "\n",
    "        for ts in trajectories[0]:\n",
    "            #(state, action, reward, next_state, done) = tuple(ts)\n",
    "            nfsp._rl_agent.feed(ts) # train the rl agent, populate the _m_rl buffer\n",
    "            loss = nfsp.train_avg_policy()\n",
    "            #nfsp.feed(ts)\n",
    "        \n",
    "#         nfsp.epochs += 1\n",
    "        if i % EVALUATE_EVERY == 0:\n",
    "            sl_loss.append(loss)\n",
    "            logger.log_performance(env.timestep, tournament(env, EVALUATION_GAMES)[0])\n",
    "        \n",
    "#         if i % 100000 == 0:\n",
    "#             nfsp.save('nfsp')\n",
    "            \n",
    "        \n",
    "            \n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
    "    \n",
    "plot_curve(csv_path, fig_path, 'nfsp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFSP vs. CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfsp wins, cfr wins, ties = (1100, 678, 222)\n"
     ]
    }
   ],
   "source": [
    "nfsp.save('nfsp')\n",
    "\n",
    "env = rlcard.make(GAME)\n",
    "env.set_agents([nfsp, agent])\n",
    "\n",
    "nfsp_wins = 0\n",
    "cfr_wins = 0\n",
    "ties = 0\n",
    "\n",
    "def evaluate_games(a1, a2, env):\n",
    "    env.set_agents([a1, a2])\n",
    "    a1_wins = 0\n",
    "    a2_wins = 0\n",
    "    ties = 0\n",
    "    episode_count = 0\n",
    "    while episode_count != EVALUATION_GAMES:\n",
    "        trajectories, payoffs = env.run(is_training=False)\n",
    "        final_state = trajectories[0][-1]\n",
    "        action_record = final_state['action_record']\n",
    "        state = final_state['raw_obs']\n",
    "        _action_list = []\n",
    "\n",
    "        for i in range(1, len(action_record)+1):\n",
    "            if action_record[-i][0] == state['current_player']:\n",
    "                break\n",
    "            _action_list.insert(0, action_record[-i])\n",
    "\n",
    "        if payoffs[0] > 0:\n",
    "            a1_wins += 1\n",
    "        elif payoffs[0] == 0:\n",
    "            ties += 1\n",
    "        else:\n",
    "            a2_wins += 1\n",
    "\n",
    "        episode_count += 1\n",
    "    \n",
    "    return a1_wins, a2_wins, ties\n",
    "\n",
    "print(f\"nfsp wins, cfr wins, ties = {evaluate_games(nfsp, agent, env)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFR vs. Rule Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule wins, cfr wins, ties = (1036, 701, 263)\n"
     ]
    }
   ],
   "source": [
    "# cfr vs. rule agent\n",
    "from rlcard.models.leducholdem_rule_models import LeducHoldemRuleAgentV1\n",
    "\n",
    "rule_agent = LeducHoldemRuleAgentV1()\n",
    "\n",
    "env = rlcard.make(GAME)\n",
    "\n",
    "print(f\"rule wins, cfr wins, ties = {evaluate_games(rule_agent, agent, env)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFR vs. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random wins, cfr wins, ties = (595, 1297, 108)\n"
     ]
    }
   ],
   "source": [
    "# cfr vs. random\n",
    "\n",
    "from rlcard.agents import RandomAgent\n",
    "\n",
    "random_agent = RandomAgent(env.num_actions)\n",
    "\n",
    "env = rlcard.make(GAME)\n",
    "\n",
    "print(f\"random wins, cfr wins, ties = {evaluate_games(random_agent, agent, env)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFSP vs Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule wins, nfsp wins, ties = (885, 730, 385)\n"
     ]
    }
   ],
   "source": [
    "# nfsp vs. rule agent\n",
    "\n",
    "rule_agent = LeducHoldemRuleAgentV1()\n",
    "\n",
    "env = rlcard.make(GAME)\n",
    "\n",
    "print(f\"rule wins, nfsp wins, ties = {evaluate_games(rule_agent, nfsp, env)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFSP vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random wins, nfsp wins, ties = (318, 1579, 103)\n"
     ]
    }
   ],
   "source": [
    "# nfsp vs. random agent\n",
    "\n",
    "from rlcard.agents import RandomAgent\n",
    "\n",
    "random_agent = RandomAgent(env.num_actions)\n",
    "\n",
    "env = rlcard.make(GAME)\n",
    "\n",
    "print(f\"random wins, nfsp wins, ties = {evaluate_games(random_agent, nfsp, env)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFR vs. Human Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Leduc Hold'em pre-trained model\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++\n",
      "Agent 1: ++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "It is a tie.\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses fold\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You win 0.5 chips!\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses check\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 0 chooses fold\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You lose 2.0 chips!\n",
      "\n",
      "Press any key to continue...1\n",
      ">> Start a new game\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   +\n",
      "Agent 1: ++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You win 4.0 chips!\n",
      "\n",
      "Press any key to continue...1\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++\n",
      "Agent 1: ++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 2\n",
      ">> Player 1 chooses check\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You win 3.0 chips!\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++\n",
      "Agent 1: ++++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You lose 6.0 chips!\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++\n",
      "Agent 1: ++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++++++\n",
      "Agent 1: ++++++++++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: fold\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> You choose action (integer): 0\n",
      ">> Player 0 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "It is a tie.\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++\n",
      "Agent 1: ++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You win 5.0 chips!\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses check\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 2\n",
      ">> Player 0 chooses check\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You lose 2.0 chips!\n",
      "\n",
      "Press any key to continue...\n",
      ">> Start a new game\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "│░░░░░░░░░│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   +\n",
      "Agent 1: ++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: raise, 2: fold\n",
      "\n",
      ">> You choose action (integer): 1\n",
      ">> Player 1 chooses call\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++\n",
      "Agent 1: ++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: raise, 1: fold, 2: check\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 1 chooses raise\n",
      "\n",
      "=============== Community Card ===============\n",
      "┌─────────┐\n",
      "│Q        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        Q│\n",
      "└─────────┘\n",
      "===============   Your Hand    ===============\n",
      "┌─────────┐\n",
      "│K        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♥    │\n",
      "│         │\n",
      "│         │\n",
      "│        K│\n",
      "└─────────┘\n",
      "===============     Chips      ===============\n",
      "Yours:   ++++++++\n",
      "Agent 1: ++++++++++++\n",
      "=========== Actions You Can Choose ===========\n",
      "0: call, 1: fold\n",
      "\n",
      ">> You choose action (integer): 0\n",
      ">> Player 0 chooses call\n",
      "===============     CFR Agent    ===============\n",
      "┌─────────┐\n",
      "│J        │\n",
      "│         │\n",
      "│         │\n",
      "│    ♠    │\n",
      "│         │\n",
      "│         │\n",
      "│        J│\n",
      "└─────────┘\n",
      "===============     Result     ===============\n",
      "You win 6.0 chips!\n",
      "\n",
      "Press any key to continue...\n",
      "Total score human, cfr, ties = (5, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "env = rlcard.make('leduc-holdem')\n",
    "human_agent = HumanAgent(env.num_actions)\n",
    "agent = CFRAgent(env, 'leduc', 'models')\n",
    "agent.load()\n",
    "env.set_agents([human_agent, agent])\n",
    "\n",
    "print(\">> Leduc Hold'em pre-trained model\")\n",
    "\n",
    "n_games = 10\n",
    "total_games = 0\n",
    "games_human_won = 0\n",
    "games_cfr_won = 0\n",
    "games_tied = 0\n",
    "\n",
    "while (total_games != n_games):\n",
    "    print(\">> Start a new game\")\n",
    "\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "    # If the human does not take the final action, we need to\n",
    "    # print other players action\n",
    "    final_state = trajectories[0][-1]\n",
    "    action_record = final_state['action_record']\n",
    "    state = final_state['raw_obs']\n",
    "    _action_list = []\n",
    "    for i in range(1, len(action_record)+1):\n",
    "        if action_record[-i][0] == state['current_player']:\n",
    "            break\n",
    "        _action_list.insert(0, action_record[-i])\n",
    "    for pair in _action_list:\n",
    "        print('>> Player', pair[0], 'chooses', pair[1])\n",
    "\n",
    "    # Let's take a look at what the agent card is\n",
    "    print('===============     CFR Agent    ===============')\n",
    "    print_card(env.get_perfect_information()['hand_cards'][1])\n",
    "\n",
    "    print('===============     Result     ===============')\n",
    "    if payoffs[0] > 0:\n",
    "        print('You win {} chips!'.format(payoffs[0]))\n",
    "        games_human_won += 1\n",
    "    elif payoffs[0] == 0:\n",
    "        print('It is a tie.')\n",
    "        games_tied += 1\n",
    "    else:\n",
    "        print('You lose {} chips!'.format(-payoffs[0]))\n",
    "        games_cfr_won += 1\n",
    "    print('')\n",
    "    total_games += 1\n",
    "\n",
    "    input(\"Press any key to continue...\")\n",
    "\n",
    "print(f'Total score human, cfr, ties = {games_human_won, games_cfr_won, games_tied}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
